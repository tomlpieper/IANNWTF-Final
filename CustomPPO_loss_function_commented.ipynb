{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, ReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Environment\n",
    "\n",
    "\n",
    "import gym\n",
    "# Further support\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.signal\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrajectoryStorage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Storage:\n",
    "    '''\n",
    "    Contains all information the agent collects interacting with the environment.\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initializes empty lists as storages all observation variables during trajectory\n",
    "        '''\n",
    "        # Saves information about the current state of the agent at each step\n",
    "        self.observations = []\n",
    "\n",
    "        # Saves actions made and rewards achieved\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        # Outputs from the actor network, an action is sampled from (Probabilities)\n",
    "        self.logits = []\n",
    "        # Outputs from the crtitics network (Values)\n",
    "        self.BaselineEstimate = []\n",
    "\n",
    "        # finished episodes will be completely stored in this list \n",
    "        self.episodes = []\n",
    "\n",
    "\n",
    "    def store(self, observation, action, logits, reward, BaselineEstimate):\n",
    "        '''\n",
    "        Adds given information to the storage.\n",
    "\n",
    "        Args:\n",
    "        observation(obj): information (e.g. pixel values) about current state of agent\n",
    "        action(float): Output of the actor network. Describes the action taken\n",
    "        logits():\n",
    "        reward(floats): Rewards collected by agent\n",
    "        BaselineEstimate():\n",
    "        '''\n",
    "        self.observations.append(observation)\n",
    "        self.actions.append(action)\n",
    "        self.logits.append(logits)\n",
    "        self.rewards.append(reward)\n",
    "        self.BaselineEstimate.append(BaselineEstimate) \n",
    "        \n",
    "\n",
    "    def conclude_episode(self):\n",
    "        '''\n",
    "        Append all collected values to episodes list once one episode is finished.\n",
    "        Computes all rewards collected in one episode. Prepares storage for next episode.\n",
    "        '''\n",
    "        self.episodes.append(\n",
    "            [self.observations,\n",
    "             self.actions, \n",
    "             self.logits,\n",
    "             self.rewards,\n",
    "             self.BaselineEstimate,\n",
    "             # Get the return of the whole episode \n",
    "             sum(self.rewards)])\n",
    "             \n",
    "        # Empty the arrays for new trajectory\n",
    "        self.observations.clear()\n",
    "        self.actions.clear()\n",
    "        self.logits.clear()\n",
    "        self.rewards.clear()\n",
    "        self.BaselineEstimate.clear()\n",
    "\n",
    "     \n",
    "    def get_episodes(self):\n",
    "        '''\n",
    "        Returns list containing finished trajectories stored in self.episodes\n",
    "        and the amount of episodes passed.\n",
    "        '''\n",
    "        return self.episodes, len(self.episodes)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(Model):\n",
    "    '''\n",
    "    Neural network computing the actions the agent will take\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialize layer architecture for Actor Network.\n",
    "        '''\n",
    "        # Subclassing API\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        self.l = [\n",
    "            # Three Dense Layers with random initial parameters having a standart deviation of 0.01\n",
    "            Dense(128, activation=\"relu\", kernel_initializer=tf.random_normal_initializer\n",
    "            (stddev=0.01)),\n",
    "            Dense(128, activation=\"relu\", kernel_initializer=tf.random_normal_initializer\n",
    "            (stddev=0.01)),\n",
    "            Dense(64, activation=\"relu\", kernel_initializer=tf.random_normal_initializer\n",
    "            (stddev=0.01)),\n",
    "            \n",
    "            # Output layer with softmax activation function applied to for neurons.\n",
    "            # Outputs prpobability for each of our for actions \n",
    "            # (Do nothing, fire left orientation engine, fire main engine, fire right orientation engine)\n",
    "            Dense(4, activation=\"softmax\")\n",
    "        ]\n",
    "\n",
    "\n",
    "    #@tf.function        \n",
    "    def call(self, x):\n",
    "        '''\n",
    "        Iterates input x through network to create softmax ouutput.\n",
    "\n",
    "        Args:\n",
    "        x(): Network input. Pixel values representing the current state of the agent\n",
    "        '''\n",
    "        for l in self.l:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    #####  logits = actor(observation) -> actor must be in capitol, gets instantiated twice, maybe idea is wrong\n",
    "    #@tf.function\n",
    "    def sample_action(self,observation):\n",
    "        '''\n",
    "        Calls the actor network with state of the agent and returns the network object + the samnpled action\n",
    "\n",
    "        Args:\n",
    "        observation(): Representation of actors state. Same as x in the call function. \n",
    "        '''\n",
    "        # Output of softmax function\n",
    "        #logits = self.call(observation)\n",
    "        logits = self(observation)\n",
    "    # tf.print(type(logits))\n",
    "        # Sample action from the Softmax output of the network\n",
    "        action = tf.squeeze(tf.random.categorical(logits, 1), axis=1)\n",
    "    # tf.print(action)\n",
    "        return logits, action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(Model):\n",
    "    '''\n",
    "    Represents the value function of the network. \n",
    "    Input is a certain state and output a float value for that state.\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialize layer architecture for Actor Network.\n",
    "        '''\n",
    "        # Subclassing API\n",
    "        super(Critic, self).__init__()\n",
    "        self.l = [\n",
    "            # Three Dense Layers with ReLu activation function\n",
    "            # Random initial parameters having a standart deviation of 0.01\n",
    "            \n",
    "            Dense(128, activation=\"relu\", kernel_initializer=tf.random_normal_initializer\n",
    "            (stddev=0.01)),\n",
    "            Dense(128, activation=\"relu\", kernel_initializer=tf.random_normal_initializer\n",
    "            (stddev=0.01)),\n",
    "            Dense(64, activation=\"relu\", kernel_initializer=tf.random_normal_initializer\n",
    "            (stddev=0.01)),\n",
    "\n",
    "            # Output layer with Tanh activation function to get float output value ([-1;1])\n",
    "            # Random initial parameters having a standart deviation of 0.01\n",
    "            Dense(1, activation=\"tanh\", kernel_regularizer=tf.random_normal_initializer(stddev=0.01))\n",
    "        ]\n",
    "\n",
    "\n",
    "    #@tf.function \n",
    "    def call(self, x):\n",
    "        '''\n",
    "        Iterates input x through network to create tanh output between -1 and 1 \n",
    "        giving input state x a value.\n",
    "\n",
    "        Args:\n",
    "        x(): Network input. Pixel values representing the current state of the agent.\n",
    "        '''\n",
    "        for l in self.l:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Adjust Hyperparameters\n",
    "'''\n",
    "\n",
    "# Number of iterations\n",
    "epochs = 10\n",
    "# Leads to ~10 Episodes per epoch, then compute new parameters (smaller batching)\n",
    "steps_per_epoch = 1000 \n",
    "\n",
    "# Learning rate for actor and critic\n",
    "lr_actor = 3e-4\n",
    "lr_critic = 3e-4\n",
    "\n",
    "# Movements in environment (state-space) to collect training data\n",
    "train_policy_iterations = 80\n",
    "train_value_iterations = 80\n",
    "\n",
    "# Parameter to decide how strongly the policy ratio gets clipped therefore how much policy (actor network)\n",
    "#  updates we allow\n",
    "# The selected 0.2 is the number proposed by the original paper by OpenAI\n",
    "clip_ratio = 0.2\n",
    "# Weighs loss of critic model\n",
    "c_1 = 0.5\n",
    "\n",
    "#\n",
    "target_kl = 0.01\n",
    "\n",
    "\n",
    "# Update weights with Adam optimizer\n",
    "optimizer = Adam()\n",
    "\n",
    "# To toggle displaying of environment\n",
    "render = False\n",
    "\n",
    "# Discount variable for rewards to whey immediate rewards stronger\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset all states generated by Keras\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Define environment\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "# Get dimensions of state and amount of possible actions (4 for LunarLander-v2)\n",
    "observation_dimensions = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "# create Storage object to save observations, actions, rewards etc. during trajectory\n",
    "#storage = Storage()\n",
    "\n",
    "# initialize actor and critics model\n",
    "#observation_input = Input(shape=(observation_dimensions,), dtype=tf.float32)\n",
    "# actor = Actor()\n",
    "# critic = Critic()\n",
    "\n",
    "# Initialize: observation(agent state), \n",
    "# episode return(summed rewards for singe ) and \n",
    "# episode length(amount of steps taken (=frames) before agent finished)\n",
    "# observation, episode_return, episode_length = env.reset(), 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    '''\n",
    "    ###Skizze - Not used yet\n",
    "\n",
    "    Currently contains:\n",
    "    - Collects data\n",
    "    - Training process (iterator, updater, actor loss fun)\n",
    "    - get advantage function\n",
    "    - dicount rewards function\n",
    "    - Get ratio function\n",
    "\n",
    "    Whats missing: \n",
    "    - All the FUCKING self's before variable assignment and for functions (fuck you python, even though i love you)    \n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        ''' \n",
    "        Initialize Parameters.\n",
    "        ###Maybe pass hyperparameters?\n",
    "        '''\n",
    "        self.actor = Actor()\n",
    "        self.critic = Critic()\n",
    "        self.storage = Storage()\n",
    "        #print(self.actor.trainable_variables())\n",
    "\n",
    "\n",
    "    def collect_train_data(self):\n",
    "        '''\n",
    "        Agent takes steps in environment according to current policy. Information gets saved to update policy.\n",
    "        -> Data collection\n",
    "        '''\n",
    "        observation, episode_return, episode_length = env.reset(), 0, 0\n",
    "        episodes_total = 0\n",
    "        # Iteration of whole training process\n",
    "        # for epoch in tqdm(range(epochs), desc = 'Epochs'):\n",
    "\n",
    "            # Initialize values for return, length and episodes\n",
    "            # sum_return = 0\n",
    "            # sum_length = 0\n",
    "            # num_episodes = 0\n",
    "\n",
    "        # Each timestep t of steps_per_epoch (in paper denoted as capital T)\n",
    "        #  allows takes on action in a state and saves the information in storage object\n",
    "        for t in tqdm(range(steps_per_epoch)):\n",
    "\n",
    "            # Toggles displaying of environment\n",
    "            # if render or epoch == epochs-1 and epochs != 1:\n",
    "            #     env.render()\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            # Reshaping observation to fit as input for Actor network (policy)\n",
    "            observation = observation.reshape(1,-1)\n",
    "            \n",
    "            # Obtain action and logits for this observation by our actor\n",
    "            logits, action = self.actor.sample_action(observation)\n",
    "            \n",
    "            # Take action in environment and obtain the rewards for it\n",
    "            # Variable done represents wether agent has finished \n",
    "            # The last variable would be diagnostic information, not needed for training\n",
    "            observation_new, reward, done, _ = env.step(action[0].numpy())\n",
    "\n",
    "            # Sum up rewards over this episode and count amount of frames\n",
    "            episode_return += reward\n",
    "            episode_length += 1\n",
    "\n",
    "            # Get the Base-Estimate from the Critics network\n",
    "            base_estimate = self.critic(observation)\n",
    "\n",
    "            # Store Variables collected in this timestep t\n",
    "            self.storage.store(observation=observation, action=action, logits=logits, reward=reward, BaselineEstimate=base_estimate)\n",
    "            # Save the new state of our agent\n",
    "            observation = observation_new\n",
    "            \n",
    "            # Check if terminal state is reached in environment\n",
    "            if done:\n",
    "                # Save information about episode\n",
    "                self.storage.conclude_episode()\n",
    "                # Refresh environment and reset return and length value\n",
    "                observation, episode_return, episode_length = env.reset(), 0, 0\n",
    "\n",
    "        # obtain all episodes saved in storage\n",
    "        # episodes, amount_episodes = self.storage.get_episodes()\n",
    "\n",
    "\n",
    "    def update_policy(self, episodes, optimizer, clip_param, c_1 = 1, c_2=0.01):\n",
    "        '''\n",
    "        Update policy with the collected data (Parameter updates for actor)\n",
    "\n",
    "        Args: \n",
    "        episodes(list): Contains all information on one episode in the following order:\n",
    "                        [observations, actions, logits, rewards, BaselineEstimate, summed rewards]\n",
    "        actor(object): Object of the actor model.\n",
    "        critic(object): Object of the critic model.\n",
    "        actor_loss(function): Clipped objective function for PPO.\n",
    "        optimizer(object): Optimizer used to train actor.\n",
    "        clip_param(float): Hyperparameter to decide values to clip ratio between.\n",
    "        c_1(float): hyperparameter to determine how strongly loss of the critic network should be weighed\n",
    "        c_2(float): hyperparameter to determine how strongly entropy should be weighed\n",
    "\n",
    "\n",
    "        Information stored as:\n",
    "        storage.episodes[different episodes]\n",
    "                        [observations, actions, logits, rewards, BaselineEstimate, sum(self.rewards)]\n",
    "                        [look at single one]\n",
    "        '''\n",
    "        # for epoch in training_iteratins:\n",
    "        # Save network loss\n",
    "        train_losses_actor = []\n",
    "        train_losses_critic = []\n",
    "        \n",
    "        # Iterate over all finished episodes from collected training data\n",
    "        for episode in tqdm(episodes):\n",
    "\n",
    "            # Update parameters\n",
    "            # Compute train losses and action by chosen by policy\n",
    "            actor_loss, critic_loss = self.train_step(\n",
    "                # States\n",
    "                episode[0],\n",
    "                # Actions\n",
    "                episode[1],\n",
    "                #optimizer (Adam)\n",
    "                optimizer,\n",
    "                # Logits\n",
    "                episode[2],\n",
    "                # Rewards\n",
    "                episode[3],\n",
    "                clip_param,\n",
    "                c_1,\n",
    "                c_2 \n",
    "            )\n",
    "            train_losses_actor.append(actor_loss)\n",
    "            train_losses_critic.append(critic_loss)\n",
    "\n",
    "            return train_losses_actor, train_losses_critic\n",
    "\n",
    "\n",
    "    def train_step(self, states, actions, optimizer, train_logits, train_rewards, clip_param, c_1, c_2):\n",
    "        '''\n",
    "        Updates actor network parameters and returns the loss to evaluate performance.\n",
    "\n",
    "        Args:\n",
    "        model(object): Object of the actor model.\n",
    "        input(list): contains floats describing the actors state.\n",
    "        loss_function(function): Clipped objective function for PPO.\n",
    "        optimizer(object): Optimizer used to train actor.\n",
    "        train_logits():\n",
    "        train_rewards():\n",
    "        clip_param():\n",
    "        c_1(): \n",
    "        c_2():\n",
    "        '''\n",
    "\n",
    "        \n",
    "\n",
    "        # use tf.gradientTape to compute loss, then gradients and apply these to the model to modify the parameters\n",
    "        with tf.GradientTape() as tape, tf.GradientTape() as tape2:\n",
    "            # print(self.actor.trainable_variables())\n",
    "            # Obtain action and logits for this state selected by policy\n",
    "            #print(f' Observation shape/type {observation}')\n",
    "            #print(f'Trainables: {self.actor.layers[0].weights}')\n",
    "\n",
    "\n",
    "            # logits_new, actions_new = sample_action(states)\n",
    "            logits_new = []\n",
    "            b_estimates_new = []\n",
    "\n",
    "            # Compute values with updated critic network\n",
    "            # b_estimates_new = critic(states)\n",
    "\n",
    "            # till we work with np arrays we need to sample each action for this by looping through it\n",
    "            for i in states:\n",
    "                logits, _ = self.actor.sample_action(i)\n",
    "                logits_new.append(logits)\n",
    "                b_estimate = self.critic(i)\n",
    "                \n",
    "                b_estimates_new.append(b_estimate)\n",
    "\n",
    "            # Compute & weigh entropy \n",
    "            #entropy = c_2 * np.mean(-(logits_new * train_logits))   # <----- DOESNT WORK YET Musste ich erstmal rausnehmen für den Rest vom Debugging\n",
    "            # entropy = 0.01\n",
    "\n",
    "            # Computes MSE between output of the critics network (value) the discounted sum of rewards\n",
    "            #  which represents an estimate based on rewards collected during training\n",
    "            # critic_loss = c_1 * tf.keras.losses.MeanSquaredError(b_estimates_new, self.discounted_reward(train_rewards)).numpy()\n",
    "            #print('Weewoo')\n",
    "            #print(tf.reduce_mean((np.array(train_rewards) - tf.convert_to_tensor(b_estimates_new, dtype=tf.float32)) ** 2))\n",
    "            critic_loss = tf.reduce_mean((np.array(train_rewards) - tf.convert_to_tensor(b_estimates_new, dtype=tf.float32)) ** 2)\n",
    "            #actor_loss = entropy * self.actor_loss_fun(actions, train_logits, logits_new, train_rewards, b_estimates_new, clip_param)\n",
    "            #actor_loss = self.actor_loss_fun(actions, train_logits, logits_new, train_rewards, b_estimates_new, clip_param)\n",
    "            #actor_loss = tf.convert_to_tensor(actor_loss)\n",
    "            #critic_loss = tf.cast(critic_loss, dtype=tf.float32)\n",
    "            #print(f'Critics loss:{type(critic_loss)}. Actor Loss {actor_loss.dtype}')\n",
    "\n",
    "            print('Actor weights')\n",
    "            print(self.critic.layers[0].weights)\n",
    "\n",
    "            #a_gradients = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "            c_gradients = tape2.gradient(critic_loss, self.critic.trainable_variables)\n",
    "            \n",
    "            actor_loss = 0\n",
    "            #print(tape)\n",
    "            #print('Actor loss')\n",
    "            #print(actor_loss)\n",
    "            #print('Trainable Weights')\n",
    "            #print(self.actor.trainable_weights)\n",
    "        \n",
    "        #print(f'Gradients Actor: {a_gradients}. Gradients Critic: {c_gradients}')\n",
    "\n",
    "        # Update parameters\n",
    "        #optimizer.apply_gradients(zip(a_gradients, self.actor.trainable_variables))\n",
    "        optimizer.apply_gradients(zip(c_gradients, self.critic.trainable_variables))\n",
    "\n",
    "        print(\"updated weights\")\n",
    "        print(self.critic.layers[0].weights)\n",
    "\n",
    "        \n",
    "\n",
    "        return actor_loss, critic_loss\n",
    "\n",
    "\n",
    "    def actor_loss_fun(self, actions, logits_old, logits_new, rewards, b_estimates_new, clip_param):\n",
    "        '''\n",
    "        Computes loss for Actor Network output.\n",
    "\n",
    "        Args:\n",
    "        logits_old():\n",
    "        logits_new():\n",
    "        reward():\n",
    "        b_estimates_new():\n",
    "        clip_param():\n",
    "        '''\n",
    "        \n",
    "        ratio = self.get_ratio_episode(actions, logits_old, logits_new)\n",
    "\n",
    "        ### FIND OUT WHICH: SINGLE OR MULTIPLE ELEMENTS ARE WANTED AND ADJUST EITHER IN GET_ADV OR THE UPPER TWO FUNCTIONS\n",
    "        advantage = self.get_advantage(rewards, b_estimates_new)\n",
    "        \n",
    "        # Unclipped value\n",
    "        l1 = ratio * advantage\n",
    "        # Clipped ratio between values determined by Hyperparam and multiplied by advantage (see objective function)\n",
    "        l2 = np.clip(ratio, a_min=1 - clip_param, a_max=1 + clip_param) * advantage\n",
    "        l1 = tf.convert_to_tensor(l1)\n",
    "        l2 = tf.convert_to_tensor(l2)\n",
    "        \n",
    "        # Compute minimum of both and take the mean to return float loss\n",
    "        actor_loss = -tf.reduce_mean(tf.minimum(l1, l2))\n",
    "        return actor_loss\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    def get_advantage(self, rewards, b_estimates, gamma = 0.99):\n",
    "        '''\n",
    "        Computes Advantage for action in state.\n",
    "\n",
    "        Args:\n",
    "        rewards(float): Reward for action.\n",
    "        gamma(float): Discount factor.\n",
    "        b_estimates(float): Baseline Estimates.\n",
    "        \n",
    "        '''\n",
    "        # Saves list of all rewards in new variable \n",
    "        #rewards = episodes[0][3]\n",
    "\n",
    "\n",
    "        # Get discounted sum of rewards \n",
    "        disc_sum = self.discounted_reward(rewards, gamma)\n",
    "\n",
    "\n",
    "        # # Estimated Value of the current situtation from the critics network\n",
    "        # b_estimates = self.episodes[0][4] \n",
    "\n",
    "        # Convert lists to np arrays and flatten\n",
    "        disc_sum_np = np.array(disc_sum)\n",
    "        b_estimates_np = np.array(b_estimates)\n",
    "        b_estimates_np = b_estimates_np.flatten()\n",
    "\n",
    "        # substract arrays to obtain advantages\n",
    "        advantages = np.subtract(disc_sum_np, b_estimates_np)\n",
    "\n",
    "        return advantages\n",
    "\n",
    "\n",
    "     ### MIGHT NOT WORK\n",
    "    #  output for: discounted_reward([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 0.99)\n",
    "    #  -> [8.91, 7.920000000000001, 6.930000000000001, 5.94, 4.95, 3.96, 2.9699999999999998, 1.98, 0.99, 0]\n",
    "    #  ###\n",
    "    def discounted_reward(self, rewards, gamma = 0.99):\n",
    "        '''\n",
    "        weighs all rewards in a way such that immediate rewards have a stronger impact than possible future rewards.\n",
    "\n",
    "        Args:\n",
    "        rewards(list): list of all rewards collected by the agent in episode t (?)\n",
    "        gamma(float): Hyperparameter determining how much future rewards should be weighed in\n",
    "        '''\n",
    "        # To select the next reward\n",
    "        i = 0\n",
    "        discounted_rewards = []\n",
    "\n",
    "        # Iterates through every reward and appends a discounted version to the output\n",
    "        for r in rewards:\n",
    "            disc = 0\n",
    "            for t in rewards[i:-1]:\n",
    "                discount_t = gamma ** t\n",
    "                disc += t * discount_t\n",
    "            i += 1\n",
    "            discounted_rewards.append(disc)\n",
    "\n",
    "        # returns list of discounted rewards.\n",
    "        return discounted_rewards   \n",
    "\n",
    "\n",
    "\n",
    "    ## get ratio lutsch noch ARSCH, das Ding verarscht mich anders\n",
    "\n",
    "    def get_ratio_episode(self, actions, logits_old, logits_new): \n",
    "        r = []\n",
    "        for a, o, n in zip(actions, logits_old, logits_new):\n",
    "            o = tf.convert_to_tensor(o)\n",
    "            n = tf.convert_to_tensor(n)\n",
    "            #print(f'A: {a} O: {type(o)} N: {type(n)}')\n",
    "\n",
    "            #get the Logarithmic version of all logits for computational efficiency\n",
    "            log_prob_old = tf.nn.log_softmax(o)\n",
    "            log_prob_new = tf.nn.log_softmax(n)\n",
    "\n",
    "            # encode in OneHotVector and reduce to sum, giving the log_prob for the action the agent took for both policies\n",
    "            logprobability_old = tf.reduce_sum(\n",
    "                tf.one_hot(a, num_actions) * log_prob_old, axis=1\n",
    "            )\n",
    "            logprobability_new = tf.reduce_sum(\n",
    "                tf.one_hot(a, num_actions) * log_prob_new, axis=1\n",
    "            )\n",
    "            # get the ratio of new over old prob\n",
    "            ratio = tf.exp(logprobability_new - logprobability_old)\n",
    "            r.append(ratio)\n",
    "        return r\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        for epoch in tqdm(range(epochs), desc=str(epochs)):\n",
    "            self.collect_train_data()\n",
    "            data, _ = self.storage.get_episodes()\n",
    "            #print(data)\n",
    "            self.update_policy(data, optimizer, clip_ratio)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 259.58it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "10:  10%|█         | 1/10 [00:04<00:37,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00590714,  0.0123431 , -0.01353293, ...,  0.01070632,\n",
      "         0.02066741, -0.04164343],\n",
      "       [-0.01133195, -0.00058727,  0.00548537, ..., -0.00211708,\n",
      "        -0.01763518,  0.00022721],\n",
      "       [ 0.01235563,  0.00057025,  0.01588361, ..., -0.00657793,\n",
      "         0.01395506,  0.00834802],\n",
      "       ...,\n",
      "       [-0.00907882, -0.00623742, -0.0039287 , ..., -0.00079001,\n",
      "         0.00231977, -0.01399863],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01332614,  0.02134664, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00092428]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00566075,  0.0123431 , -0.01389103, ...,  0.01070632,\n",
      "         0.02037184, -0.0416933 ],\n",
      "       [-0.01213689, -0.00058727,  0.00648026, ..., -0.00211708,\n",
      "        -0.01693899,  0.00121712],\n",
      "       [ 0.01188577,  0.00057025,  0.01504584, ..., -0.00657793,\n",
      "         0.01334865,  0.00781164],\n",
      "       ...,\n",
      "       [-0.00932669, -0.00623742, -0.0030102 , ..., -0.00079001,\n",
      "         0.00287123, -0.01461196],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01332614,  0.02134664, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00092428]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 0.00064285,  0.        ,  0.00099365,  0.        ,  0.00098309,\n",
      "       -0.00097545,  0.        ,  0.        , -0.00099612, -0.00090434,\n",
      "        0.00098281, -0.00094671,  0.        ,  0.00099613,  0.00072647,\n",
      "       -0.00099727, -0.00099316,  0.        ,  0.        , -0.00098307,\n",
      "        0.        ,  0.00098251, -0.00099603,  0.00099711, -0.00049299,\n",
      "        0.00099616, -0.00098653, -0.00094815, -0.00097426,  0.00094692,\n",
      "        0.        , -0.00099516,  0.00099801, -0.00099674,  0.        ,\n",
      "        0.00098861,  0.00097142,  0.00091569, -0.00099148, -0.00087284,\n",
      "        0.        ,  0.0009874 , -0.000998  ,  0.00099541,  0.00088302,\n",
      "       -0.00098821,  0.        , -0.00082402,  0.        ,  0.00099602,\n",
      "        0.00099102,  0.00090313,  0.        , -0.00099806, -0.00099682,\n",
      "        0.00096408, -0.00098692,  0.        , -0.00097916, -0.0009962 ,\n",
      "        0.00095158,  0.00089745,  0.        , -0.00091056,  0.        ,\n",
      "        0.        ,  0.0009081 ,  0.        , -0.00099701,  0.00093397,\n",
      "       -0.00099131, -0.00098963,  0.00096018, -0.00081222, -0.00098249,\n",
      "        0.0009956 , -0.00099595, -0.00093919,  0.        , -0.00099259,\n",
      "        0.00097857, -0.0009981 ,  0.00099493, -0.0009961 ,  0.00099727,\n",
      "        0.00098171,  0.0009956 ,  0.00099784,  0.        ,  0.0009724 ,\n",
      "       -0.00097807, -0.00094734, -0.00099568,  0.        , -0.00086004,\n",
      "        0.        ,  0.        , -0.00096644, -0.00098307,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00099249,  0.00091934,\n",
      "        0.00093957,  0.00099392,  0.        ,  0.00098909,  0.        ,\n",
      "        0.        ,  0.00096241, -0.00072217, -0.00099011, -0.00099162,\n",
      "       -0.00095843,  0.        ,  0.00099398, -0.00099338, -0.0009873 ,\n",
      "        0.00098622,  0.        ,  0.        , -0.00099121, -0.00099498,\n",
      "        0.        ,  0.00089878,  0.00098652], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 289.28it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "10:  20%|██        | 2/10 [00:07<00:30,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00566075,  0.0123431 , -0.01389103, ...,  0.01070632,\n",
      "         0.02037184, -0.0416933 ],\n",
      "       [-0.01213689, -0.00058727,  0.00648026, ..., -0.00211708,\n",
      "        -0.01693899,  0.00121712],\n",
      "       [ 0.01188577,  0.00057025,  0.01504584, ..., -0.00657793,\n",
      "         0.01334865,  0.00781164],\n",
      "       ...,\n",
      "       [-0.00932669, -0.00623742, -0.0030102 , ..., -0.00079001,\n",
      "         0.00287123, -0.01461196],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01332614,  0.02134664, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00092428]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 0.00064285,  0.        ,  0.00099365,  0.        ,  0.00098309,\n",
      "       -0.00097545,  0.        ,  0.        , -0.00099612, -0.00090434,\n",
      "        0.00098281, -0.00094671,  0.        ,  0.00099613,  0.00072647,\n",
      "       -0.00099727, -0.00099316,  0.        ,  0.        , -0.00098307,\n",
      "        0.        ,  0.00098251, -0.00099603,  0.00099711, -0.00049299,\n",
      "        0.00099616, -0.00098653, -0.00094815, -0.00097426,  0.00094692,\n",
      "        0.        , -0.00099516,  0.00099801, -0.00099674,  0.        ,\n",
      "        0.00098861,  0.00097142,  0.00091569, -0.00099148, -0.00087284,\n",
      "        0.        ,  0.0009874 , -0.000998  ,  0.00099541,  0.00088302,\n",
      "       -0.00098821,  0.        , -0.00082402,  0.        ,  0.00099602,\n",
      "        0.00099102,  0.00090313,  0.        , -0.00099806, -0.00099682,\n",
      "        0.00096408, -0.00098692,  0.        , -0.00097916, -0.0009962 ,\n",
      "        0.00095158,  0.00089745,  0.        , -0.00091056,  0.        ,\n",
      "        0.        ,  0.0009081 ,  0.        , -0.00099701,  0.00093397,\n",
      "       -0.00099131, -0.00098963,  0.00096018, -0.00081222, -0.00098249,\n",
      "        0.0009956 , -0.00099595, -0.00093919,  0.        , -0.00099259,\n",
      "        0.00097857, -0.0009981 ,  0.00099493, -0.0009961 ,  0.00099727,\n",
      "        0.00098171,  0.0009956 ,  0.00099784,  0.        ,  0.0009724 ,\n",
      "       -0.00097807, -0.00094734, -0.00099568,  0.        , -0.00086004,\n",
      "        0.        ,  0.        , -0.00096644, -0.00098307,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.00099249,  0.00091934,\n",
      "        0.00093957,  0.00099392,  0.        ,  0.00098909,  0.        ,\n",
      "        0.        ,  0.00096241, -0.00072217, -0.00099011, -0.00099162,\n",
      "       -0.00095843,  0.        ,  0.00099398, -0.00099338, -0.0009873 ,\n",
      "        0.00098622,  0.        ,  0.        , -0.00099121, -0.00099498,\n",
      "        0.        ,  0.00089878,  0.00098652], dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00549572,  0.0119762 , -0.01376882, ...,  0.01070632,\n",
      "         0.02017385, -0.04184141],\n",
      "       [-0.01267619,  0.00015463,  0.0062977 , ..., -0.00211708,\n",
      "        -0.01647258,  0.00217053],\n",
      "       [ 0.01157102, -0.00013831,  0.01550773, ..., -0.00657793,\n",
      "         0.0129424 ,  0.00708863],\n",
      "       ...,\n",
      "       [-0.00949272, -0.00689792, -0.0021062 , ..., -0.00079001,\n",
      "         0.00324066, -0.01530967],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01332614,  0.02134664, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00092428]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 0.00107352,  0.00074093,  0.00088118,  0.        ,  0.00164182,\n",
      "       -0.00162905,  0.        ,  0.        , -0.00191502, -0.00151026,\n",
      "        0.00164135, -0.00158104,  0.        ,  0.00125337,  0.00121317,\n",
      "       -0.00166549, -0.00192048,  0.        ,  0.00074196, -0.00144739,\n",
      "       -0.00073119,  0.00030938, -0.00199363,  0.00144502, -0.00123697,\n",
      "        0.00049898, -0.00164756, -0.00158344, -0.0017526 ,  0.00158139,\n",
      "        0.        , -0.001986  ,  0.00077092, -0.00082133,  0.        ,\n",
      "        0.0003509 ,  0.00029845,  0.00019259, -0.0018708 , -0.00097841,\n",
      "        0.        ,  0.00181048, -0.00196377,  0.00061662,  0.00014729,\n",
      "       -0.00165036,  0.        , -0.00137611,  0.        ,  0.00072059,\n",
      "        0.00042551,  0.00150824,  0.        , -0.00181943, -0.00166475,\n",
      "        0.00174413, -0.00169838,  0.        , -0.00038147, -0.00197966,\n",
      "        0.00022291,  0.00149876, -0.00074184, -0.00182775,  0.        ,\n",
      "        0.        ,  0.00151655, -0.00073979, -0.00166506,  0.00155976,\n",
      "       -0.00114122, -0.00046891,  0.00160354, -0.0013564 , -0.00048714,\n",
      "        0.00038889, -0.00193712, -0.00156849,  0.        , -0.00165768,\n",
      "        0.00027485, -0.00178665,  0.00122677, -0.00166355,  0.0005057 ,\n",
      "        0.00030944,  0.00103555,  0.00055319,  0.        ,  0.00033751,\n",
      "       -0.00163343, -0.00027368, -0.00166283,  0.        , -0.00143627,\n",
      "        0.        ,  0.        , -0.00097657, -0.0019405 ,  0.        ,\n",
      "        0.00071473,  0.        ,  0.        , -0.00039738,  0.00153532,\n",
      "        0.00022062,  0.00036574,  0.        ,  0.00039412,  0.        ,\n",
      "        0.        ,  0.00160727, -0.00120599, -0.00165354, -0.00195888,\n",
      "       -0.00160061, -0.00074187,  0.00193994, -0.00179774, -0.0019323 ,\n",
      "        0.00064916,  0.        ,  0.        , -0.00192545, -0.00166168,\n",
      "        0.        ,  0.00150098,  0.00192801], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 291.32it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "10:  30%|███       | 3/10 [00:11<00:26,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00549572,  0.0119762 , -0.01376882, ...,  0.01070632,\n",
      "         0.02017385, -0.04184141],\n",
      "       [-0.01267619,  0.00015463,  0.0062977 , ..., -0.00211708,\n",
      "        -0.01647258,  0.00217053],\n",
      "       [ 0.01157102, -0.00013831,  0.01550773, ..., -0.00657793,\n",
      "         0.0129424 ,  0.00708863],\n",
      "       ...,\n",
      "       [-0.00949272, -0.00689792, -0.0021062 , ..., -0.00079001,\n",
      "         0.00324066, -0.01530967],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01332614,  0.02134664, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00092428]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 0.00107352,  0.00074093,  0.00088118,  0.        ,  0.00164182,\n",
      "       -0.00162905,  0.        ,  0.        , -0.00191502, -0.00151026,\n",
      "        0.00164135, -0.00158104,  0.        ,  0.00125337,  0.00121317,\n",
      "       -0.00166549, -0.00192048,  0.        ,  0.00074196, -0.00144739,\n",
      "       -0.00073119,  0.00030938, -0.00199363,  0.00144502, -0.00123697,\n",
      "        0.00049898, -0.00164756, -0.00158344, -0.0017526 ,  0.00158139,\n",
      "        0.        , -0.001986  ,  0.00077092, -0.00082133,  0.        ,\n",
      "        0.0003509 ,  0.00029845,  0.00019259, -0.0018708 , -0.00097841,\n",
      "        0.        ,  0.00181048, -0.00196377,  0.00061662,  0.00014729,\n",
      "       -0.00165036,  0.        , -0.00137611,  0.        ,  0.00072059,\n",
      "        0.00042551,  0.00150824,  0.        , -0.00181943, -0.00166475,\n",
      "        0.00174413, -0.00169838,  0.        , -0.00038147, -0.00197966,\n",
      "        0.00022291,  0.00149876, -0.00074184, -0.00182775,  0.        ,\n",
      "        0.        ,  0.00151655, -0.00073979, -0.00166506,  0.00155976,\n",
      "       -0.00114122, -0.00046891,  0.00160354, -0.0013564 , -0.00048714,\n",
      "        0.00038889, -0.00193712, -0.00156849,  0.        , -0.00165768,\n",
      "        0.00027485, -0.00178665,  0.00122677, -0.00166355,  0.0005057 ,\n",
      "        0.00030944,  0.00103555,  0.00055319,  0.        ,  0.00033751,\n",
      "       -0.00163343, -0.00027368, -0.00166283,  0.        , -0.00143627,\n",
      "        0.        ,  0.        , -0.00097657, -0.0019405 ,  0.        ,\n",
      "        0.00071473,  0.        ,  0.        , -0.00039738,  0.00153532,\n",
      "        0.00022062,  0.00036574,  0.        ,  0.00039412,  0.        ,\n",
      "        0.        ,  0.00160727, -0.00120599, -0.00165354, -0.00195888,\n",
      "       -0.00160061, -0.00074187,  0.00193994, -0.00179774, -0.0019323 ,\n",
      "        0.00064916,  0.        ,  0.        , -0.00192545, -0.00166168,\n",
      "        0.        ,  0.00150098,  0.00192801], dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.0053682 ,  0.0113404 , -0.0143284 , ...,  0.01070632,\n",
      "         0.02002086, -0.04247082],\n",
      "       [-0.01309304,  0.0010059 ,  0.00642092, ..., -0.00211708,\n",
      "        -0.01611209,  0.00296423],\n",
      "       [ 0.01132778, -0.00085184,  0.01500138, ..., -0.00657793,\n",
      "         0.01262842,  0.00644049],\n",
      "       ...,\n",
      "       [-0.00962101, -0.00650159, -0.00117559, ..., -0.00079001,\n",
      "         0.00352617, -0.01473431],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01332614,  0.02134664, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00092428]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 1.4063733e-03,  1.5863483e-03,  1.0266597e-03,  0.0000000e+00,\n",
      "        2.1510101e-03, -2.1342745e-03,  0.0000000e+00,  0.0000000e+00,\n",
      "       -2.3644043e-03, -1.9786276e-03,  2.1503973e-03, -2.0713743e-03,\n",
      "        0.0000000e+00,  1.4518686e-03,  1.5893503e-03, -2.1820283e-03,\n",
      "       -2.6373009e-03,  0.0000000e+00,  5.2502705e-04, -8.8203052e-04,\n",
      "       -1.2964003e-03,  2.6177068e-04, -2.3492256e-03,  2.1692391e-03,\n",
      "       -9.1273349e-04,  5.9079763e-04, -2.1585352e-03, -2.0745136e-03,\n",
      "       -1.4588839e-03,  2.2458492e-03,  0.0000000e+00, -2.7012066e-03,\n",
      "        1.2589359e-03, -1.1926736e-03,  0.0000000e+00,  4.9837469e-04,\n",
      "        6.8493583e-04, -3.6637799e-04, -1.9569462e-03, -1.6173832e-03,\n",
      "        0.0000000e+00,  2.0552787e-03, -2.5538548e-03,  8.4599556e-04,\n",
      "        2.4230396e-04, -2.1621985e-03,  0.0000000e+00, -1.8028393e-03,\n",
      "        0.0000000e+00,  5.0358754e-04,  6.8670377e-04,  2.1691395e-03,\n",
      "        0.0000000e+00, -2.6282943e-03, -2.1810571e-03,  2.2714394e-03,\n",
      "       -2.2483524e-03,  0.0000000e+00, -6.1130302e-04, -2.7398746e-03,\n",
      "        4.3331538e-04,  1.9635500e-03, -1.3152868e-03, -2.5367255e-03,\n",
      "        6.3441310e-04,  0.0000000e+00,  1.9868608e-03, -1.3116573e-03,\n",
      "       -2.1814699e-03,  2.0434808e-03, -1.7894763e-03, -9.6008519e-04,\n",
      "        2.1008528e-03, -1.7770201e-03, -8.2011498e-04,  6.3597452e-04,\n",
      "       -2.1532960e-03, -1.0406888e-03,  6.2434387e-04, -2.4368684e-03,\n",
      "       -2.6912155e-04, -2.5102342e-03,  1.8841638e-03, -2.1794860e-03,\n",
      "        1.2570430e-04,  6.7950226e-05,  1.0552632e-03,  5.9658877e-04,\n",
      "        0.0000000e+00,  3.0993318e-04, -2.1400156e-03,  3.9246347e-04,\n",
      "       -2.1785491e-03,  0.0000000e+00, -1.8816695e-03,  0.0000000e+00,\n",
      "        0.0000000e+00, -1.6146175e-03, -1.5717515e-03,  0.0000000e+00,\n",
      "        1.4233310e-04,  0.0000000e+00,  0.0000000e+00, -7.3894893e-04,\n",
      "        2.0114586e-03, -6.1237853e-04,  5.0880644e-04,  0.0000000e+00,\n",
      "       -3.8413639e-04,  0.0000000e+00,  0.0000000e+00,  2.1057469e-03,\n",
      "       -1.5799413e-03, -2.1663660e-03, -2.7065822e-03, -2.0970153e-03,\n",
      "       -3.4609926e-04,  1.5926560e-03, -2.6119365e-03, -1.4754925e-03,\n",
      "        7.5510179e-05,  6.1711750e-04,  0.0000000e+00, -2.8570727e-03,\n",
      "       -2.1770373e-03,  0.0000000e+00,  1.9664653e-03,  2.7378229e-03],\n",
      "      dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 275.68it/s]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\n",
      "10:  40%|████      | 4/10 [00:15<00:23,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.0053682 ,  0.0113404 , -0.0143284 , ...,  0.01070632,\n",
      "         0.02002086, -0.04247082],\n",
      "       [-0.01309304,  0.0010059 ,  0.00642092, ..., -0.00211708,\n",
      "        -0.01611209,  0.00296423],\n",
      "       [ 0.01132778, -0.00085184,  0.01500138, ..., -0.00657793,\n",
      "         0.01262842,  0.00644049],\n",
      "       ...,\n",
      "       [-0.00962101, -0.00650159, -0.00117559, ..., -0.00079001,\n",
      "         0.00352617, -0.01473431],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01332614,  0.02134664, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00092428]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 1.4063733e-03,  1.5863483e-03,  1.0266597e-03,  0.0000000e+00,\n",
      "        2.1510101e-03, -2.1342745e-03,  0.0000000e+00,  0.0000000e+00,\n",
      "       -2.3644043e-03, -1.9786276e-03,  2.1503973e-03, -2.0713743e-03,\n",
      "        0.0000000e+00,  1.4518686e-03,  1.5893503e-03, -2.1820283e-03,\n",
      "       -2.6373009e-03,  0.0000000e+00,  5.2502705e-04, -8.8203052e-04,\n",
      "       -1.2964003e-03,  2.6177068e-04, -2.3492256e-03,  2.1692391e-03,\n",
      "       -9.1273349e-04,  5.9079763e-04, -2.1585352e-03, -2.0745136e-03,\n",
      "       -1.4588839e-03,  2.2458492e-03,  0.0000000e+00, -2.7012066e-03,\n",
      "        1.2589359e-03, -1.1926736e-03,  0.0000000e+00,  4.9837469e-04,\n",
      "        6.8493583e-04, -3.6637799e-04, -1.9569462e-03, -1.6173832e-03,\n",
      "        0.0000000e+00,  2.0552787e-03, -2.5538548e-03,  8.4599556e-04,\n",
      "        2.4230396e-04, -2.1621985e-03,  0.0000000e+00, -1.8028393e-03,\n",
      "        0.0000000e+00,  5.0358754e-04,  6.8670377e-04,  2.1691395e-03,\n",
      "        0.0000000e+00, -2.6282943e-03, -2.1810571e-03,  2.2714394e-03,\n",
      "       -2.2483524e-03,  0.0000000e+00, -6.1130302e-04, -2.7398746e-03,\n",
      "        4.3331538e-04,  1.9635500e-03, -1.3152868e-03, -2.5367255e-03,\n",
      "        6.3441310e-04,  0.0000000e+00,  1.9868608e-03, -1.3116573e-03,\n",
      "       -2.1814699e-03,  2.0434808e-03, -1.7894763e-03, -9.6008519e-04,\n",
      "        2.1008528e-03, -1.7770201e-03, -8.2011498e-04,  6.3597452e-04,\n",
      "       -2.1532960e-03, -1.0406888e-03,  6.2434387e-04, -2.4368684e-03,\n",
      "       -2.6912155e-04, -2.5102342e-03,  1.8841638e-03, -2.1794860e-03,\n",
      "        1.2570430e-04,  6.7950226e-05,  1.0552632e-03,  5.9658877e-04,\n",
      "        0.0000000e+00,  3.0993318e-04, -2.1400156e-03,  3.9246347e-04,\n",
      "       -2.1785491e-03,  0.0000000e+00, -1.8816695e-03,  0.0000000e+00,\n",
      "        0.0000000e+00, -1.6146175e-03, -1.5717515e-03,  0.0000000e+00,\n",
      "        1.4233310e-04,  0.0000000e+00,  0.0000000e+00, -7.3894893e-04,\n",
      "        2.0114586e-03, -6.1237853e-04,  5.0880644e-04,  0.0000000e+00,\n",
      "       -3.8413639e-04,  0.0000000e+00,  0.0000000e+00,  2.1057469e-03,\n",
      "       -1.5799413e-03, -2.1663660e-03, -2.7065822e-03, -2.0970153e-03,\n",
      "       -3.4609926e-04,  1.5926560e-03, -2.6119365e-03, -1.4754925e-03,\n",
      "        7.5510179e-05,  6.1711750e-04,  0.0000000e+00, -2.8570727e-03,\n",
      "       -2.1770373e-03,  0.0000000e+00,  1.9664653e-03,  2.7378229e-03],\n",
      "      dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00480201,  0.01059739, -0.01505103, ...,  0.01106913,\n",
      "         0.0205855 , -0.043239  ],\n",
      "       [-0.01261595,  0.00190937,  0.00674527, ..., -0.00269401,\n",
      "        -0.01662355,  0.00383209],\n",
      "       [ 0.01075117, -0.00167422,  0.01429653, ..., -0.00600696,\n",
      "         0.01310961,  0.00565497],\n",
      "       ...,\n",
      "       [-0.00913124, -0.00588566, -0.00023921, ..., -0.00132977,\n",
      "         0.00295114, -0.01399286],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01383333,  0.02191368, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00142926]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 1.9903800e-03,  2.4881670e-03,  1.3675510e-03, -5.6877412e-04,\n",
      "        2.8151842e-03, -1.6026157e-03,  0.0000000e+00,  5.7714223e-04,\n",
      "       -2.4938912e-03, -2.3622622e-03,  2.7457292e-03, -2.4730104e-03,\n",
      "        5.7924562e-04,  2.0427480e-03,  2.1783269e-03, -2.6121414e-03,\n",
      "       -3.1796356e-03,  5.7443470e-04,  2.5044830e-04, -2.9360689e-04,\n",
      "       -1.0282900e-03,  6.8988261e-04, -2.4651301e-03,  2.8843624e-03,\n",
      "       -2.8181000e-04,  1.0049613e-03, -2.8679506e-03, -1.5598517e-03,\n",
      "       -9.1596670e-04,  2.9302624e-03, -5.7749636e-04, -3.2870565e-03,\n",
      "        1.9194337e-03, -1.6776255e-03,  0.0000000e+00,  1.0519067e-03,\n",
      "        1.1791813e-03, -8.2424533e-04, -1.9011182e-03, -2.3129852e-03,\n",
      "        0.0000000e+00,  2.0837584e-03, -3.3003935e-03,  1.2949782e-03,\n",
      "        7.3982647e-04, -2.8760764e-03,  0.0000000e+00, -1.2595756e-03,\n",
      "       -5.7432364e-04,  7.6895813e-04,  1.1445032e-03,  2.8770668e-03,\n",
      "        0.0000000e+00, -3.3119791e-03, -2.7908850e-03,  2.4988372e-03,\n",
      "       -1.7360913e-03,  4.9646187e-04, -6.1446376e-04, -3.3625932e-03,\n",
      "        9.8919577e-04,  2.5532059e-03, -1.7850162e-03, -3.3279778e-03,\n",
      "        1.3507819e-03,  5.7826657e-04,  2.5859526e-03, -1.8316393e-03,\n",
      "       -1.9683866e-03,  2.6338468e-03, -2.3095838e-03, -1.5676829e-03,\n",
      "        2.7188521e-03, -2.1215298e-03, -9.3818828e-04,  1.2096881e-03,\n",
      "       -1.8314007e-03, -4.1980820e-04,  1.1357594e-03, -2.6716592e-03,\n",
      "       -7.0533011e-04, -3.2685520e-03,  2.6041898e-03, -2.8894413e-03,\n",
      "       -1.3745879e-04,  5.3173699e-04,  1.5780893e-03,  9.7897684e-04,\n",
      "        5.6983711e-04,  8.3521428e-04, -2.5549757e-03,  1.1115480e-03,\n",
      "       -1.8567170e-03,  0.0000000e+00, -1.3052577e-03,  5.7866407e-04,\n",
      "        4.3709279e-04, -2.3178265e-03, -1.0204599e-03,  0.0000000e+00,\n",
      "       -3.2653607e-04,  0.0000000e+00,  0.0000000e+00, -1.1694067e-03,\n",
      "        2.6027802e-03, -1.2661124e-03,  8.4497925e-04,  5.4598268e-04,\n",
      "       -1.0601149e-03,  5.7691464e-04, -5.7282299e-04,  2.7027004e-03,\n",
      "       -1.8862128e-03, -2.0693422e-03, -2.1997755e-03, -1.6899469e-03,\n",
      "        9.0682239e-05,  1.1664524e-03, -3.2788739e-03, -8.0321525e-04,\n",
      "        3.9722794e-04,  9.5567142e-05,  5.7212054e-04, -3.4003318e-03,\n",
      "       -2.7685543e-03, -5.7515816e-04,  1.4413337e-03,  3.6004570e-03],\n",
      "      dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 265.79it/s]\n",
      "  0%|          | 0/51 [00:00<?, ?it/s]\n",
      "10:  50%|█████     | 5/10 [00:19<00:19,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00480201,  0.01059739, -0.01505103, ...,  0.01106913,\n",
      "         0.0205855 , -0.043239  ],\n",
      "       [-0.01261595,  0.00190937,  0.00674527, ..., -0.00269401,\n",
      "        -0.01662355,  0.00383209],\n",
      "       [ 0.01075117, -0.00167422,  0.01429653, ..., -0.00600696,\n",
      "         0.01310961,  0.00565497],\n",
      "       ...,\n",
      "       [-0.00913124, -0.00588566, -0.00023921, ..., -0.00132977,\n",
      "         0.00295114, -0.01399286],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01383333,  0.02191368, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00142926]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 1.9903800e-03,  2.4881670e-03,  1.3675510e-03, -5.6877412e-04,\n",
      "        2.8151842e-03, -1.6026157e-03,  0.0000000e+00,  5.7714223e-04,\n",
      "       -2.4938912e-03, -2.3622622e-03,  2.7457292e-03, -2.4730104e-03,\n",
      "        5.7924562e-04,  2.0427480e-03,  2.1783269e-03, -2.6121414e-03,\n",
      "       -3.1796356e-03,  5.7443470e-04,  2.5044830e-04, -2.9360689e-04,\n",
      "       -1.0282900e-03,  6.8988261e-04, -2.4651301e-03,  2.8843624e-03,\n",
      "       -2.8181000e-04,  1.0049613e-03, -2.8679506e-03, -1.5598517e-03,\n",
      "       -9.1596670e-04,  2.9302624e-03, -5.7749636e-04, -3.2870565e-03,\n",
      "        1.9194337e-03, -1.6776255e-03,  0.0000000e+00,  1.0519067e-03,\n",
      "        1.1791813e-03, -8.2424533e-04, -1.9011182e-03, -2.3129852e-03,\n",
      "        0.0000000e+00,  2.0837584e-03, -3.3003935e-03,  1.2949782e-03,\n",
      "        7.3982647e-04, -2.8760764e-03,  0.0000000e+00, -1.2595756e-03,\n",
      "       -5.7432364e-04,  7.6895813e-04,  1.1445032e-03,  2.8770668e-03,\n",
      "        0.0000000e+00, -3.3119791e-03, -2.7908850e-03,  2.4988372e-03,\n",
      "       -1.7360913e-03,  4.9646187e-04, -6.1446376e-04, -3.3625932e-03,\n",
      "        9.8919577e-04,  2.5532059e-03, -1.7850162e-03, -3.3279778e-03,\n",
      "        1.3507819e-03,  5.7826657e-04,  2.5859526e-03, -1.8316393e-03,\n",
      "       -1.9683866e-03,  2.6338468e-03, -2.3095838e-03, -1.5676829e-03,\n",
      "        2.7188521e-03, -2.1215298e-03, -9.3818828e-04,  1.2096881e-03,\n",
      "       -1.8314007e-03, -4.1980820e-04,  1.1357594e-03, -2.6716592e-03,\n",
      "       -7.0533011e-04, -3.2685520e-03,  2.6041898e-03, -2.8894413e-03,\n",
      "       -1.3745879e-04,  5.3173699e-04,  1.5780893e-03,  9.7897684e-04,\n",
      "        5.6983711e-04,  8.3521428e-04, -2.5549757e-03,  1.1115480e-03,\n",
      "       -1.8567170e-03,  0.0000000e+00, -1.3052577e-03,  5.7866407e-04,\n",
      "        4.3709279e-04, -2.3178265e-03, -1.0204599e-03,  0.0000000e+00,\n",
      "       -3.2653607e-04,  0.0000000e+00,  0.0000000e+00, -1.1694067e-03,\n",
      "        2.6027802e-03, -1.2661124e-03,  8.4497925e-04,  5.4598268e-04,\n",
      "       -1.0601149e-03,  5.7691464e-04, -5.7282299e-04,  2.7027004e-03,\n",
      "       -1.8862128e-03, -2.0693422e-03, -2.1997755e-03, -1.6899469e-03,\n",
      "        9.0682239e-05,  1.1664524e-03, -3.2788739e-03, -8.0321525e-04,\n",
      "        3.9722794e-04,  9.5567142e-05,  5.7212054e-04, -3.4003318e-03,\n",
      "       -2.7685543e-03, -5.7515816e-04,  1.4413337e-03,  3.6004570e-03],\n",
      "      dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00432345,  0.01040426, -0.01491295, ...,  0.01137573,\n",
      "         0.02106274, -0.04377332],\n",
      "       [-0.0122127 ,  0.00257963,  0.00733486, ..., -0.00318164,\n",
      "        -0.01705584,  0.00469262],\n",
      "       [ 0.0102638 , -0.00136485,  0.0146851 , ..., -0.00552436,\n",
      "         0.01351631,  0.00539047],\n",
      "       ...,\n",
      "       [-0.0087173 , -0.00604364, -0.00066743, ..., -0.00178597,\n",
      "         0.00246512, -0.01409157],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01426199,  0.02239295, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00185606]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 2.4839947e-03,  3.1628935e-03,  1.9594566e-03, -1.0495131e-03,\n",
      "        3.3765619e-03, -9.5161243e-04,  0.0000000e+00,  1.0649577e-03,\n",
      "       -2.1440263e-03, -2.6865057e-03,  3.4837676e-03, -2.8124757e-03,\n",
      "        1.0688397e-03,  2.7245013e-03,  2.6761428e-03, -2.9756848e-03,\n",
      "       -3.8917307e-03,  1.0599605e-03,  1.8366700e-05,  4.1462923e-04,\n",
      "       -8.0167665e-04,  1.3415421e-03, -2.5902574e-03,  3.6853061e-03,\n",
      "        4.4630701e-04,  1.6324990e-03, -3.4675668e-03, -1.1248465e-03,\n",
      "       -2.6770221e-04,  3.7040159e-03, -1.0656113e-03, -3.9737322e-03,\n",
      "        2.6998725e-03, -1.9584899e-03,  0.0000000e+00,  1.7599615e-03,\n",
      "        1.8368112e-03, -9.8529900e-04, -1.9787378e-03, -3.0655428e-03,\n",
      "        0.0000000e+00,  1.6235493e-03, -4.0964806e-03,  1.9510407e-03,\n",
      "        1.4284021e-03, -3.4794644e-03,  0.0000000e+00, -8.0039690e-04,\n",
      "       -1.0597555e-03,  1.3504995e-03,  1.7898113e-03,  3.4754267e-03,\n",
      "        0.0000000e+00, -4.1053877e-03, -3.5347864e-03,  2.1851151e-03,\n",
      "       -1.0837447e-03,  9.1605505e-04, -1.1269975e-04, -4.1007730e-03,\n",
      "        1.7090329e-03,  3.0515993e-03, -1.9439631e-03, -3.9967601e-03,\n",
      "        1.9562752e-03,  1.0670328e-03,  3.1875027e-03, -2.2711416e-03,\n",
      "       -1.7882827e-03,  3.1328406e-03, -2.7491935e-03, -2.2609439e-03,\n",
      "        3.3167740e-03, -2.4126917e-03, -5.2505720e-04,  1.9074932e-03,\n",
      "       -1.2279609e-03,  3.3138710e-04,  1.5680175e-03, -2.8701108e-03,\n",
      "       -7.6520478e-04, -3.7971623e-03,  3.3967656e-03, -3.4939675e-03,\n",
      "        1.6901709e-04,  9.2374266e-04,  2.2679330e-03,  1.6041829e-03,\n",
      "        1.0514751e-03,  1.5114450e-03, -2.9057078e-03,  1.8767227e-03,\n",
      "       -1.5846958e-03,  0.0000000e+00, -8.1805832e-04,  1.0677665e-03,\n",
      "        8.0649025e-04, -2.9334631e-03, -3.2469560e-04,  0.0000000e+00,\n",
      "       -7.2283682e-04,  0.0000000e+00,  0.0000000e+00, -1.5614966e-03,\n",
      "        3.1025815e-03, -1.8186666e-03,  1.4033292e-03,  1.0074488e-03,\n",
      "       -1.3963112e-03,  1.0645376e-03, -1.0569859e-03,  3.2072621e-03,\n",
      "       -2.1450464e-03, -1.9873353e-03, -1.5231253e-03, -1.3458835e-03,\n",
      "        4.5986226e-04,  1.0583260e-03, -3.9029475e-03, -7.5988239e-05,\n",
      "        9.8958262e-04, -3.4526124e-04,  1.0556894e-03, -3.0212984e-03,\n",
      "       -3.2685199e-03, -1.0612957e-03,  9.9748024e-04,  4.4571906e-03],\n",
      "      dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 280.21it/s]\n",
      "  0%|          | 0/61 [00:00<?, ?it/s]\n",
      "10:  60%|██████    | 6/10 [00:23<00:15,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00432345,  0.01040426, -0.01491295, ...,  0.01137573,\n",
      "         0.02106274, -0.04377332],\n",
      "       [-0.0122127 ,  0.00257963,  0.00733486, ..., -0.00318164,\n",
      "        -0.01705584,  0.00469262],\n",
      "       [ 0.0102638 , -0.00136485,  0.0146851 , ..., -0.00552436,\n",
      "         0.01351631,  0.00539047],\n",
      "       ...,\n",
      "       [-0.0087173 , -0.00604364, -0.00066743, ..., -0.00178597,\n",
      "         0.00246512, -0.01409157],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01426199,  0.02239295, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00185606]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 2.4839947e-03,  3.1628935e-03,  1.9594566e-03, -1.0495131e-03,\n",
      "        3.3765619e-03, -9.5161243e-04,  0.0000000e+00,  1.0649577e-03,\n",
      "       -2.1440263e-03, -2.6865057e-03,  3.4837676e-03, -2.8124757e-03,\n",
      "        1.0688397e-03,  2.7245013e-03,  2.6761428e-03, -2.9756848e-03,\n",
      "       -3.8917307e-03,  1.0599605e-03,  1.8366700e-05,  4.1462923e-04,\n",
      "       -8.0167665e-04,  1.3415421e-03, -2.5902574e-03,  3.6853061e-03,\n",
      "        4.4630701e-04,  1.6324990e-03, -3.4675668e-03, -1.1248465e-03,\n",
      "       -2.6770221e-04,  3.7040159e-03, -1.0656113e-03, -3.9737322e-03,\n",
      "        2.6998725e-03, -1.9584899e-03,  0.0000000e+00,  1.7599615e-03,\n",
      "        1.8368112e-03, -9.8529900e-04, -1.9787378e-03, -3.0655428e-03,\n",
      "        0.0000000e+00,  1.6235493e-03, -4.0964806e-03,  1.9510407e-03,\n",
      "        1.4284021e-03, -3.4794644e-03,  0.0000000e+00, -8.0039690e-04,\n",
      "       -1.0597555e-03,  1.3504995e-03,  1.7898113e-03,  3.4754267e-03,\n",
      "        0.0000000e+00, -4.1053877e-03, -3.5347864e-03,  2.1851151e-03,\n",
      "       -1.0837447e-03,  9.1605505e-04, -1.1269975e-04, -4.1007730e-03,\n",
      "        1.7090329e-03,  3.0515993e-03, -1.9439631e-03, -3.9967601e-03,\n",
      "        1.9562752e-03,  1.0670328e-03,  3.1875027e-03, -2.2711416e-03,\n",
      "       -1.7882827e-03,  3.1328406e-03, -2.7491935e-03, -2.2609439e-03,\n",
      "        3.3167740e-03, -2.4126917e-03, -5.2505720e-04,  1.9074932e-03,\n",
      "       -1.2279609e-03,  3.3138710e-04,  1.5680175e-03, -2.8701108e-03,\n",
      "       -7.6520478e-04, -3.7971623e-03,  3.3967656e-03, -3.4939675e-03,\n",
      "        1.6901709e-04,  9.2374266e-04,  2.2679330e-03,  1.6041829e-03,\n",
      "        1.0514751e-03,  1.5114450e-03, -2.9057078e-03,  1.8767227e-03,\n",
      "       -1.5846958e-03,  0.0000000e+00, -8.1805832e-04,  1.0677665e-03,\n",
      "        8.0649025e-04, -2.9334631e-03, -3.2469560e-04,  0.0000000e+00,\n",
      "       -7.2283682e-04,  0.0000000e+00,  0.0000000e+00, -1.5614966e-03,\n",
      "        3.1025815e-03, -1.8186666e-03,  1.4033292e-03,  1.0074488e-03,\n",
      "       -1.3963112e-03,  1.0645376e-03, -1.0569859e-03,  3.2072621e-03,\n",
      "       -2.1450464e-03, -1.9873353e-03, -1.5231253e-03, -1.3458835e-03,\n",
      "        4.5986226e-04,  1.0583260e-03, -3.9029475e-03, -7.5988239e-05,\n",
      "        9.8958262e-04, -3.4526124e-04,  1.0556894e-03, -3.0212984e-03,\n",
      "       -3.2685199e-03, -1.0612957e-03,  9.9748024e-04,  4.4571906e-03],\n",
      "      dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00375709,  0.01016461, -0.01504733, ...,  0.01163993,\n",
      "         0.02147405, -0.044333  ],\n",
      "       [-0.01159272,  0.00321357,  0.00791307, ..., -0.00360191,\n",
      "        -0.01742841,  0.00551071],\n",
      "       [ 0.00967006, -0.00113457,  0.01495658, ..., -0.00510842,\n",
      "         0.01386681,  0.00510534],\n",
      "       ...,\n",
      "       [-0.00813914, -0.00616573, -0.00100158, ..., -0.00217914,\n",
      "         0.00204623, -0.01413095],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01463142,  0.02280601, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00222389]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 3.1488342e-03,  3.7963837e-03,  2.5427709e-03, -1.4638451e-03,\n",
      "        3.9364183e-03, -2.8120511e-04,  0.0000000e+00,  1.4853918e-03,\n",
      "       -1.7440260e-03, -2.9659492e-03,  4.2047636e-03, -3.1050441e-03,\n",
      "        1.4908074e-03,  3.3956848e-03,  3.3453612e-03, -3.1754952e-03,\n",
      "       -4.5220554e-03,  1.6816786e-03, -1.9420794e-04,  1.0597575e-03,\n",
      "       -6.0636527e-04,  1.9924664e-03, -2.6808570e-03,  4.4473498e-03,\n",
      "        1.1579995e-03,  2.2466490e-03, -3.9843586e-03, -7.4022019e-04,\n",
      "        3.5480212e-04,  4.4536204e-03, -1.4863035e-03, -4.5669544e-03,\n",
      "        3.4437052e-03, -2.1403753e-03,  0.0000000e+00,  2.4445334e-03,\n",
      "        2.4652663e-03, -9.7783445e-04, -2.0060567e-03, -3.7386529e-03,\n",
      "        0.0000000e+00,  1.1992038e-03, -4.8199245e-03,  2.5831694e-03,\n",
      "        2.1057506e-03, -3.9995071e-03,  0.0000000e+00, -2.3855118e-04,\n",
      "       -1.4781342e-03,  1.9553686e-03,  2.4372595e-03,  4.1649789e-03,\n",
      "        0.0000000e+00, -4.8078881e-03, -4.1777682e-03,  1.9107608e-03,\n",
      "       -4.4076191e-04,  1.2776651e-03,  4.1452696e-04, -4.7369907e-03,\n",
      "        2.4003254e-03,  3.6647345e-03, -2.0809553e-03, -4.5731603e-03,\n",
      "        2.6307302e-03,  1.4882867e-03,  3.7640957e-03, -2.6499364e-03,\n",
      "       -1.4971937e-03,  3.6575892e-03, -3.1280813e-03, -2.8646390e-03,\n",
      "        3.8955391e-03, -2.6636131e-03, -9.9507946e-05,  2.5627112e-03,\n",
      "       -6.2558736e-04,  1.0933366e-03,  1.9819997e-03, -2.9902023e-03,\n",
      "       -7.4798591e-04, -4.1905954e-03,  4.1643269e-03, -3.9848355e-03,\n",
      "        4.9996644e-04,  1.4036325e-03,  2.9506625e-03,  2.2210421e-03,\n",
      "        1.4665822e-03,  2.1835801e-03, -3.2079914e-03,  2.6346168e-03,\n",
      "       -1.1764965e-03,  0.0000000e+00, -2.9698381e-04,  1.4893103e-03,\n",
      "        1.1248249e-03, -3.4555765e-03,  3.8782245e-04,  0.0000000e+00,\n",
      "       -1.0620133e-03,  0.0000000e+00,  0.0000000e+00, -1.8832020e-03,\n",
      "        3.6661983e-03, -2.2933176e-03,  1.9515255e-03,  1.6005110e-03,\n",
      "       -1.6123443e-03,  1.4848057e-03, -1.4742704e-03,  3.7466432e-03,\n",
      "       -2.3680972e-03, -1.8673023e-03, -8.7221380e-04, -7.7787606e-04,\n",
      "        8.2269649e-04,  1.0055653e-03, -4.4437717e-03,  6.0433522e-04,\n",
      "        1.6030035e-03, -7.2519912e-04,  1.7043087e-03, -2.5977634e-03,\n",
      "       -3.6711365e-03, -1.4802830e-03,  6.1493670e-04,  5.2818158e-03],\n",
      "      dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 269.61it/s]\n",
      "  0%|          | 0/72 [00:00<?, ?it/s]\n",
      "10:  70%|███████   | 7/10 [00:27<00:11,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00375709,  0.01016461, -0.01504733, ...,  0.01163993,\n",
      "         0.02147405, -0.044333  ],\n",
      "       [-0.01159272,  0.00321357,  0.00791307, ..., -0.00360191,\n",
      "        -0.01742841,  0.00551071],\n",
      "       [ 0.00967006, -0.00113457,  0.01495658, ..., -0.00510842,\n",
      "         0.01386681,  0.00510534],\n",
      "       ...,\n",
      "       [-0.00813914, -0.00616573, -0.00100158, ..., -0.00217914,\n",
      "         0.00204623, -0.01413095],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01463142,  0.02280601, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00222389]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 3.1488342e-03,  3.7963837e-03,  2.5427709e-03, -1.4638451e-03,\n",
      "        3.9364183e-03, -2.8120511e-04,  0.0000000e+00,  1.4853918e-03,\n",
      "       -1.7440260e-03, -2.9659492e-03,  4.2047636e-03, -3.1050441e-03,\n",
      "        1.4908074e-03,  3.3956848e-03,  3.3453612e-03, -3.1754952e-03,\n",
      "       -4.5220554e-03,  1.6816786e-03, -1.9420794e-04,  1.0597575e-03,\n",
      "       -6.0636527e-04,  1.9924664e-03, -2.6808570e-03,  4.4473498e-03,\n",
      "        1.1579995e-03,  2.2466490e-03, -3.9843586e-03, -7.4022019e-04,\n",
      "        3.5480212e-04,  4.4536204e-03, -1.4863035e-03, -4.5669544e-03,\n",
      "        3.4437052e-03, -2.1403753e-03,  0.0000000e+00,  2.4445334e-03,\n",
      "        2.4652663e-03, -9.7783445e-04, -2.0060567e-03, -3.7386529e-03,\n",
      "        0.0000000e+00,  1.1992038e-03, -4.8199245e-03,  2.5831694e-03,\n",
      "        2.1057506e-03, -3.9995071e-03,  0.0000000e+00, -2.3855118e-04,\n",
      "       -1.4781342e-03,  1.9553686e-03,  2.4372595e-03,  4.1649789e-03,\n",
      "        0.0000000e+00, -4.8078881e-03, -4.1777682e-03,  1.9107608e-03,\n",
      "       -4.4076191e-04,  1.2776651e-03,  4.1452696e-04, -4.7369907e-03,\n",
      "        2.4003254e-03,  3.6647345e-03, -2.0809553e-03, -4.5731603e-03,\n",
      "        2.6307302e-03,  1.4882867e-03,  3.7640957e-03, -2.6499364e-03,\n",
      "       -1.4971937e-03,  3.6575892e-03, -3.1280813e-03, -2.8646390e-03,\n",
      "        3.8955391e-03, -2.6636131e-03, -9.9507946e-05,  2.5627112e-03,\n",
      "       -6.2558736e-04,  1.0933366e-03,  1.9819997e-03, -2.9902023e-03,\n",
      "       -7.4798591e-04, -4.1905954e-03,  4.1643269e-03, -3.9848355e-03,\n",
      "        4.9996644e-04,  1.4036325e-03,  2.9506625e-03,  2.2210421e-03,\n",
      "        1.4665822e-03,  2.1835801e-03, -3.2079914e-03,  2.6346168e-03,\n",
      "       -1.1764965e-03,  0.0000000e+00, -2.9698381e-04,  1.4893103e-03,\n",
      "        1.1248249e-03, -3.4555765e-03,  3.8782245e-04,  0.0000000e+00,\n",
      "       -1.0620133e-03,  0.0000000e+00,  0.0000000e+00, -1.8832020e-03,\n",
      "        3.6661983e-03, -2.2933176e-03,  1.9515255e-03,  1.6005110e-03,\n",
      "       -1.6123443e-03,  1.4848057e-03, -1.4742704e-03,  3.7466432e-03,\n",
      "       -2.3680972e-03, -1.8673023e-03, -8.7221380e-04, -7.7787606e-04,\n",
      "        8.2269649e-04,  1.0055653e-03, -4.4437717e-03,  6.0433522e-04,\n",
      "        1.6030035e-03, -7.2519912e-04,  1.7043087e-03, -2.5977634e-03,\n",
      "       -3.6711365e-03, -1.4802830e-03,  6.1493670e-04,  5.2818158e-03],\n",
      "      dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.0032625 ,  0.00961837, -0.01555884, ...,  0.01187061,\n",
      "         0.02183325, -0.04503484],\n",
      "       [-0.0110513 ,  0.00395659,  0.00860697, ..., -0.00396894,\n",
      "        -0.01775377,  0.00638574],\n",
      "       [ 0.00915155, -0.00147471,  0.01465682, ..., -0.00474518,\n",
      "         0.0141729 ,  0.00455213],\n",
      "       ...,\n",
      "       [-0.00763425, -0.00602034, -0.00100877, ..., -0.00252249,\n",
      "         0.00168041, -0.01386929],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01495402,  0.02316674, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00254509]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 3.7294358e-03,  4.5412127e-03,  3.2438133e-03, -1.8256782e-03,\n",
      "        4.4253413e-03,  3.8900389e-04,  0.0000000e+00,  1.8525562e-03,\n",
      "       -1.1579429e-03, -3.2099760e-03,  5.0081429e-03, -3.3605378e-03,\n",
      "        1.8593119e-03,  4.1611004e-03,  3.9297882e-03, -3.3499897e-03,\n",
      "       -5.0725183e-03,  2.3089298e-03, -3.7984957e-04,  1.7699618e-03,\n",
      "       -4.3580023e-04,  2.7494372e-03, -2.5793198e-03,  5.2686105e-03,\n",
      "        1.9526256e-03,  2.9651062e-03, -4.4356724e-03, -4.0432657e-04,\n",
      "        1.0709635e-03,  5.2791806e-03, -1.8536936e-03, -5.0850161e-03,\n",
      "        4.2558573e-03, -2.0639349e-03,  0.0000000e+00,  3.2145292e-03,\n",
      "        3.2047448e-03, -9.7131566e-04, -1.7700284e-03, -4.4163335e-03,\n",
      "        0.0000000e+00,  8.2862226e-04, -5.5079092e-03,  3.3152404e-03,\n",
      "        2.8749162e-03, -4.4536600e-03,  0.0000000e+00,  2.5210640e-04,\n",
      "       -1.8435030e-03,  2.6853671e-03,  3.1919521e-03,  4.9163504e-03,\n",
      "        0.0000000e+00, -5.4199016e-03, -4.7392845e-03,  1.8209881e-03,\n",
      "        2.8657407e-04,  1.5934368e-03,  1.0948367e-03, -5.2926000e-03,\n",
      "        3.1666055e-03,  4.3468610e-03, -2.2005907e-03, -5.0765267e-03,\n",
      "        3.2742890e-03,  1.8561675e-03,  4.2676353e-03, -2.9807375e-03,\n",
      "       -9.8215137e-04,  4.3214131e-03, -3.4589644e-03, -3.3566633e-03,\n",
      "        4.5754369e-03, -2.8827225e-03,  5.0620630e-04,  3.2811477e-03,\n",
      "        8.3152263e-05,  1.9216138e-03,  2.5200665e-03, -2.5796713e-03,\n",
      "       -7.3294865e-04, -4.2196647e-03,  5.0024064e-03, -4.4135107e-03,\n",
      "        7.8898494e-04,  2.0580254e-03,  3.7289411e-03,  2.9365947e-03,\n",
      "        1.8290924e-03,  2.9551988e-03, -3.4719734e-03,  3.4490987e-03,\n",
      "       -5.6554365e-04,  0.0000000e+00,  3.7080195e-04,  1.8574444e-03,\n",
      "        1.4027925e-03, -3.8676327e-03,  1.1675197e-03,  0.0000000e+00,\n",
      "       -1.3582162e-03,  0.0000000e+00,  0.0000000e+00, -2.0257151e-03,\n",
      "        4.3380181e-03, -2.7078306e-03,  2.6105070e-03,  2.1889755e-03,\n",
      "       -1.4817219e-03,  1.8518252e-03, -1.8386829e-03,  4.2701196e-03,\n",
      "       -2.5628607e-03, -1.7624778e-03, -1.3147853e-04, -8.3146559e-05,\n",
      "        1.3337252e-03,  1.1209076e-03, -4.9160742e-03,  1.3602292e-03,\n",
      "        2.3380639e-03, -1.0569990e-03,  2.4142568e-03, -1.9718378e-03,\n",
      "       -4.0227412e-03, -1.8461833e-03,  2.8086279e-04,  6.1603757e-03],\n",
      "      dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 297.06it/s]\n",
      "  0%|          | 0/83 [00:00<?, ?it/s]\n",
      "10:  80%|████████  | 8/10 [00:30<00:07,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.0032625 ,  0.00961837, -0.01555884, ...,  0.01187061,\n",
      "         0.02183325, -0.04503484],\n",
      "       [-0.0110513 ,  0.00395659,  0.00860697, ..., -0.00396894,\n",
      "        -0.01775377,  0.00638574],\n",
      "       [ 0.00915155, -0.00147471,  0.01465682, ..., -0.00474518,\n",
      "         0.0141729 ,  0.00455213],\n",
      "       ...,\n",
      "       [-0.00763425, -0.00602034, -0.00100877, ..., -0.00252249,\n",
      "         0.00168041, -0.01386929],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01495402,  0.02316674, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00254509]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 3.7294358e-03,  4.5412127e-03,  3.2438133e-03, -1.8256782e-03,\n",
      "        4.4253413e-03,  3.8900389e-04,  0.0000000e+00,  1.8525562e-03,\n",
      "       -1.1579429e-03, -3.2099760e-03,  5.0081429e-03, -3.3605378e-03,\n",
      "        1.8593119e-03,  4.1611004e-03,  3.9297882e-03, -3.3499897e-03,\n",
      "       -5.0725183e-03,  2.3089298e-03, -3.7984957e-04,  1.7699618e-03,\n",
      "       -4.3580023e-04,  2.7494372e-03, -2.5793198e-03,  5.2686105e-03,\n",
      "        1.9526256e-03,  2.9651062e-03, -4.4356724e-03, -4.0432657e-04,\n",
      "        1.0709635e-03,  5.2791806e-03, -1.8536936e-03, -5.0850161e-03,\n",
      "        4.2558573e-03, -2.0639349e-03,  0.0000000e+00,  3.2145292e-03,\n",
      "        3.2047448e-03, -9.7131566e-04, -1.7700284e-03, -4.4163335e-03,\n",
      "        0.0000000e+00,  8.2862226e-04, -5.5079092e-03,  3.3152404e-03,\n",
      "        2.8749162e-03, -4.4536600e-03,  0.0000000e+00,  2.5210640e-04,\n",
      "       -1.8435030e-03,  2.6853671e-03,  3.1919521e-03,  4.9163504e-03,\n",
      "        0.0000000e+00, -5.4199016e-03, -4.7392845e-03,  1.8209881e-03,\n",
      "        2.8657407e-04,  1.5934368e-03,  1.0948367e-03, -5.2926000e-03,\n",
      "        3.1666055e-03,  4.3468610e-03, -2.2005907e-03, -5.0765267e-03,\n",
      "        3.2742890e-03,  1.8561675e-03,  4.2676353e-03, -2.9807375e-03,\n",
      "       -9.8215137e-04,  4.3214131e-03, -3.4589644e-03, -3.3566633e-03,\n",
      "        4.5754369e-03, -2.8827225e-03,  5.0620630e-04,  3.2811477e-03,\n",
      "        8.3152263e-05,  1.9216138e-03,  2.5200665e-03, -2.5796713e-03,\n",
      "       -7.3294865e-04, -4.2196647e-03,  5.0024064e-03, -4.4135107e-03,\n",
      "        7.8898494e-04,  2.0580254e-03,  3.7289411e-03,  2.9365947e-03,\n",
      "        1.8290924e-03,  2.9551988e-03, -3.4719734e-03,  3.4490987e-03,\n",
      "       -5.6554365e-04,  0.0000000e+00,  3.7080195e-04,  1.8574444e-03,\n",
      "        1.4027925e-03, -3.8676327e-03,  1.1675197e-03,  0.0000000e+00,\n",
      "       -1.3582162e-03,  0.0000000e+00,  0.0000000e+00, -2.0257151e-03,\n",
      "        4.3380181e-03, -2.7078306e-03,  2.6105070e-03,  2.1889755e-03,\n",
      "       -1.4817219e-03,  1.8518252e-03, -1.8386829e-03,  4.2701196e-03,\n",
      "       -2.5628607e-03, -1.7624778e-03, -1.3147853e-04, -8.3146559e-05,\n",
      "        1.3337252e-03,  1.1209076e-03, -4.9160742e-03,  1.3602292e-03,\n",
      "        2.3380639e-03, -1.0569990e-03,  2.4142568e-03, -1.9718378e-03,\n",
      "       -4.0227412e-03, -1.8461833e-03,  2.8086279e-04,  6.1603757e-03],\n",
      "      dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00282649,  0.00892977, -0.01622175, ...,  0.01207394,\n",
      "         0.0221499 , -0.04582629],\n",
      "       [-0.01057401,  0.00466086,  0.00931828, ..., -0.00429249,\n",
      "        -0.01804059,  0.00710252],\n",
      "       [ 0.00869446, -0.00205331,  0.01409605, ..., -0.00442497,\n",
      "         0.01444273,  0.00388551],\n",
      "       ...,\n",
      "       [-0.00718919, -0.00550887, -0.00053725, ..., -0.00282516,\n",
      "         0.00135792, -0.01333642],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01523839,  0.02348474, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00282822]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 4.2412682e-03,  5.2502924e-03,  3.9612963e-03, -2.1446524e-03,\n",
      "        4.8563555e-03,  1.0034184e-03,  0.0000000e+00,  2.1762329e-03,\n",
      "       -5.0805666e-04, -3.4250901e-03,  5.7542562e-03, -3.5857649e-03,\n",
      "        2.1841705e-03,  4.8906198e-03,  4.4506700e-03, -3.5038169e-03,\n",
      "       -5.5577843e-03,  2.9266097e-03, -5.4350379e-04,  2.4939901e-03,\n",
      "       -2.8543753e-04,  3.4590906e-03, -2.0936765e-03,  6.0565071e-03,\n",
      "        2.7004210e-03,  3.6780867e-03, -4.8335316e-03, -1.0821715e-04,\n",
      "        1.7916742e-03,  6.0296673e-03, -2.1775691e-03, -5.5417186e-03,\n",
      "        5.0326930e-03, -1.5792826e-03,  0.0000000e+00,  3.9547952e-03,\n",
      "        3.9154347e-03, -4.8096589e-04, -1.2334322e-03, -5.1517296e-03,\n",
      "        0.0000000e+00,  3.5501408e-04, -6.1121453e-03,  4.0447200e-03,\n",
      "        3.6180199e-03, -4.8540216e-03,  0.0000000e+00,  6.8464782e-04,\n",
      "       -2.1655958e-03,  3.3698666e-03,  3.8965943e-03,  5.5757686e-03,\n",
      "        0.0000000e+00, -5.8258660e-03, -5.2342946e-03,  2.2178651e-03,\n",
      "        9.6064038e-04,  1.8717883e-03,  1.7637085e-03, -5.7824031e-03,\n",
      "        3.9290674e-03,  4.9716961e-03, -2.3060562e-03, -5.5202697e-03,\n",
      "        3.8893546e-03,  2.1804757e-03,  4.7983220e-03, -3.2723579e-03,\n",
      "       -3.5016576e-04,  4.9066134e-03, -3.7506577e-03, -3.3646312e-03,\n",
      "        5.2773035e-03, -3.0758625e-03,  1.1358247e-03,  4.0408126e-03,\n",
      "        7.9935417e-04,  2.6214635e-03,  3.1772892e-03, -2.2177636e-03,\n",
      "       -7.1969238e-04, -3.7574968e-03,  5.7584541e-03, -4.7914134e-03,\n",
      "        1.3462803e-03,  2.7184333e-03,  4.4481279e-03,  3.6711390e-03,\n",
      "        2.1486641e-03,  3.6685416e-03, -3.7046866e-03,  4.1221478e-03,\n",
      "        9.4766263e-05,  0.0000000e+00,  1.0075055e-03,  2.1819761e-03,\n",
      "        1.6478074e-03, -3.6590246e-03,  1.8299257e-03,  0.0000000e+00,\n",
      "       -1.6193363e-03,  0.0000000e+00,  0.0000000e+00, -1.7054160e-03,\n",
      "        4.9302676e-03, -3.0732485e-03,  3.3128704e-03,  2.7077419e-03,\n",
      "       -9.7441499e-04,  2.1753740e-03, -2.1599324e-03,  4.7315951e-03,\n",
      "       -2.7345326e-03, -1.6700689e-03,  5.8969925e-04,  7.0099876e-04,\n",
      "        1.9716113e-03,  1.6026988e-03, -5.3324373e-03,  2.0956500e-03,\n",
      "        3.0318017e-03, -1.3494999e-03,  3.0401153e-03, -1.3392847e-03,\n",
      "       -4.3327017e-03, -2.1687450e-03, -1.3641751e-05,  6.8837288e-03],\n",
      "      dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 287.88it/s]\n",
      "  0%|          | 0/93 [00:00<?, ?it/s]\n",
      "10:  90%|█████████ | 9/10 [00:34<00:03,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00282649,  0.00892977, -0.01622175, ...,  0.01207394,\n",
      "         0.0221499 , -0.04582629],\n",
      "       [-0.01057401,  0.00466086,  0.00931828, ..., -0.00429249,\n",
      "        -0.01804059,  0.00710252],\n",
      "       [ 0.00869446, -0.00205331,  0.01409605, ..., -0.00442497,\n",
      "         0.01444273,  0.00388551],\n",
      "       ...,\n",
      "       [-0.00718919, -0.00550887, -0.00053725, ..., -0.00282516,\n",
      "         0.00135792, -0.01333642],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01523839,  0.02348474, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00282822]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 4.2412682e-03,  5.2502924e-03,  3.9612963e-03, -2.1446524e-03,\n",
      "        4.8563555e-03,  1.0034184e-03,  0.0000000e+00,  2.1762329e-03,\n",
      "       -5.0805666e-04, -3.4250901e-03,  5.7542562e-03, -3.5857649e-03,\n",
      "        2.1841705e-03,  4.8906198e-03,  4.4506700e-03, -3.5038169e-03,\n",
      "       -5.5577843e-03,  2.9266097e-03, -5.4350379e-04,  2.4939901e-03,\n",
      "       -2.8543753e-04,  3.4590906e-03, -2.0936765e-03,  6.0565071e-03,\n",
      "        2.7004210e-03,  3.6780867e-03, -4.8335316e-03, -1.0821715e-04,\n",
      "        1.7916742e-03,  6.0296673e-03, -2.1775691e-03, -5.5417186e-03,\n",
      "        5.0326930e-03, -1.5792826e-03,  0.0000000e+00,  3.9547952e-03,\n",
      "        3.9154347e-03, -4.8096589e-04, -1.2334322e-03, -5.1517296e-03,\n",
      "        0.0000000e+00,  3.5501408e-04, -6.1121453e-03,  4.0447200e-03,\n",
      "        3.6180199e-03, -4.8540216e-03,  0.0000000e+00,  6.8464782e-04,\n",
      "       -2.1655958e-03,  3.3698666e-03,  3.8965943e-03,  5.5757686e-03,\n",
      "        0.0000000e+00, -5.8258660e-03, -5.2342946e-03,  2.2178651e-03,\n",
      "        9.6064038e-04,  1.8717883e-03,  1.7637085e-03, -5.7824031e-03,\n",
      "        3.9290674e-03,  4.9716961e-03, -2.3060562e-03, -5.5202697e-03,\n",
      "        3.8893546e-03,  2.1804757e-03,  4.7983220e-03, -3.2723579e-03,\n",
      "       -3.5016576e-04,  4.9066134e-03, -3.7506577e-03, -3.3646312e-03,\n",
      "        5.2773035e-03, -3.0758625e-03,  1.1358247e-03,  4.0408126e-03,\n",
      "        7.9935417e-04,  2.6214635e-03,  3.1772892e-03, -2.2177636e-03,\n",
      "       -7.1969238e-04, -3.7574968e-03,  5.7584541e-03, -4.7914134e-03,\n",
      "        1.3462803e-03,  2.7184333e-03,  4.4481279e-03,  3.6711390e-03,\n",
      "        2.1486641e-03,  3.6685416e-03, -3.7046866e-03,  4.1221478e-03,\n",
      "        9.4766263e-05,  0.0000000e+00,  1.0075055e-03,  2.1819761e-03,\n",
      "        1.6478074e-03, -3.6590246e-03,  1.8299257e-03,  0.0000000e+00,\n",
      "       -1.6193363e-03,  0.0000000e+00,  0.0000000e+00, -1.7054160e-03,\n",
      "        4.9302676e-03, -3.0732485e-03,  3.3128704e-03,  2.7077419e-03,\n",
      "       -9.7441499e-04,  2.1753740e-03, -2.1599324e-03,  4.7315951e-03,\n",
      "       -2.7345326e-03, -1.6700689e-03,  5.8969925e-04,  7.0099876e-04,\n",
      "        1.9716113e-03,  1.6026988e-03, -5.3324373e-03,  2.0956500e-03,\n",
      "        3.0318017e-03, -1.3494999e-03,  3.0401153e-03, -1.3392847e-03,\n",
      "       -4.3327017e-03, -2.1687450e-03, -1.3641751e-05,  6.8837288e-03],\n",
      "      dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00258909,  0.00835986, -0.01676222, ...,  0.01181054,\n",
      "         0.022479  , -0.04647947],\n",
      "       [-0.0099416 ,  0.00529521,  0.00995915, ..., -0.00460033,\n",
      "        -0.0180862 ,  0.00774948],\n",
      "       [ 0.00839476, -0.00255879,  0.01360704, ..., -0.00417031,\n",
      "         0.01482833,  0.00330359],\n",
      "       ...,\n",
      "       [-0.00678624, -0.00505399, -0.00011817, ..., -0.00306046,\n",
      "         0.00106869, -0.01286285],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01549083,  0.02376704, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00307956]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 4.85643744e-03,  5.88971144e-03,  4.60895989e-03, -2.42781406e-03,\n",
      "        5.28362440e-03,  1.56041689e-03,  4.31408320e-04,  2.66807596e-03,\n",
      "        8.05705786e-05, -3.84048000e-03,  6.42771181e-03, -3.78570170e-03,\n",
      "        2.47255852e-03,  5.54972747e-03,  4.93313698e-03, -3.59910564e-03,\n",
      "       -5.97316818e-03,  3.48661863e-03, -6.91322843e-04,  3.14652594e-03,\n",
      "       -1.04212726e-04,  4.10005590e-03, -1.65347231e-03,  6.76622894e-03,\n",
      "        3.37466015e-03,  4.32259962e-03, -5.18672401e-03,  2.07547593e-04,\n",
      "        2.44254177e-03,  6.70647388e-03, -2.46508396e-03, -5.94794331e-03,\n",
      "        5.73254144e-03, -1.13609387e-03, -2.51966936e-04,  4.62317467e-03,\n",
      "        4.55735438e-03, -3.17006197e-05, -7.43330806e-04, -5.80456667e-03,\n",
      "        3.69866699e-04, -6.67814165e-05, -6.64360169e-03,  4.70270962e-03,\n",
      "        4.28689457e-03, -5.20943571e-03,  0.00000000e+00,  1.06862758e-03,\n",
      "       -2.45152717e-03,  3.98951350e-03,  4.53251461e-03,  6.17318181e-03,\n",
      "        0.00000000e+00, -6.17220113e-03, -5.65454457e-03,  2.58262875e-03,\n",
      "        1.57042348e-03,  2.11887271e-03,  2.36953818e-03, -6.21642126e-03,\n",
      "        4.61640581e-03,  5.53651154e-03, -2.38077110e-03, -5.91419218e-03,\n",
      "        4.44132928e-03,  2.46837502e-03,  5.30455960e-03, -3.53096426e-03,\n",
      "        2.24863761e-04,  5.43868728e-03, -4.00960399e-03, -3.36336624e-03,\n",
      "        5.91154862e-03, -3.24730366e-03,  1.70697132e-03,  4.72520571e-03,\n",
      "        1.44637958e-03,  3.25478474e-03,  3.79258441e-03, -1.89648534e-03,\n",
      "       -6.70115172e-04, -3.33244470e-03,  6.44052960e-03, -5.11156442e-03,\n",
      "        1.85280084e-03,  3.30755254e-03,  5.09873591e-03,  4.33384161e-03,\n",
      "        2.43235636e-03,  4.31353040e-03, -3.91127216e-03,  4.73336922e-03,\n",
      "        6.88876142e-04,  0.00000000e+00,  1.57895673e-03,  2.47007376e-03,\n",
      "        1.86528871e-03, -3.46762058e-03,  2.42804969e-03, -1.37586889e-04,\n",
      "       -1.85114134e-03,  0.00000000e+00,  0.00000000e+00, -1.41211436e-03,\n",
      "        5.46995178e-03, -3.39367613e-03,  3.94711131e-03,  3.18005774e-03,\n",
      "       -5.11971419e-04,  2.46643391e-03, -2.44511478e-03,  5.16675459e-03,\n",
      "       -2.61249067e-03, -1.58803468e-03,  1.24099408e-03,  1.47791195e-03,\n",
      "        2.53960188e-03,  2.04351451e-03, -5.70338499e-03,  2.76096864e-03,\n",
      "        3.65881785e-03, -1.60916289e-03,  3.59570887e-03, -7.68503291e-04,\n",
      "       -4.60786372e-03, -2.51274090e-03, -1.78236340e-04,  7.53808115e-03],\n",
      "      dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 303.40it/s]\n",
      "  0%|          | 0/103 [00:00<?, ?it/s]\n",
      "10: 100%|██████████| 10/10 [00:38<00:00,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00258909,  0.00835986, -0.01676222, ...,  0.01181054,\n",
      "         0.022479  , -0.04647947],\n",
      "       [-0.0099416 ,  0.00529521,  0.00995915, ..., -0.00460033,\n",
      "        -0.0180862 ,  0.00774948],\n",
      "       [ 0.00839476, -0.00255879,  0.01360704, ..., -0.00417031,\n",
      "         0.01482833,  0.00330359],\n",
      "       ...,\n",
      "       [-0.00678624, -0.00505399, -0.00011817, ..., -0.00306046,\n",
      "         0.00106869, -0.01286285],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01549083,  0.02376704, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00307956]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 4.85643744e-03,  5.88971144e-03,  4.60895989e-03, -2.42781406e-03,\n",
      "        5.28362440e-03,  1.56041689e-03,  4.31408320e-04,  2.66807596e-03,\n",
      "        8.05705786e-05, -3.84048000e-03,  6.42771181e-03, -3.78570170e-03,\n",
      "        2.47255852e-03,  5.54972747e-03,  4.93313698e-03, -3.59910564e-03,\n",
      "       -5.97316818e-03,  3.48661863e-03, -6.91322843e-04,  3.14652594e-03,\n",
      "       -1.04212726e-04,  4.10005590e-03, -1.65347231e-03,  6.76622894e-03,\n",
      "        3.37466015e-03,  4.32259962e-03, -5.18672401e-03,  2.07547593e-04,\n",
      "        2.44254177e-03,  6.70647388e-03, -2.46508396e-03, -5.94794331e-03,\n",
      "        5.73254144e-03, -1.13609387e-03, -2.51966936e-04,  4.62317467e-03,\n",
      "        4.55735438e-03, -3.17006197e-05, -7.43330806e-04, -5.80456667e-03,\n",
      "        3.69866699e-04, -6.67814165e-05, -6.64360169e-03,  4.70270962e-03,\n",
      "        4.28689457e-03, -5.20943571e-03,  0.00000000e+00,  1.06862758e-03,\n",
      "       -2.45152717e-03,  3.98951350e-03,  4.53251461e-03,  6.17318181e-03,\n",
      "        0.00000000e+00, -6.17220113e-03, -5.65454457e-03,  2.58262875e-03,\n",
      "        1.57042348e-03,  2.11887271e-03,  2.36953818e-03, -6.21642126e-03,\n",
      "        4.61640581e-03,  5.53651154e-03, -2.38077110e-03, -5.91419218e-03,\n",
      "        4.44132928e-03,  2.46837502e-03,  5.30455960e-03, -3.53096426e-03,\n",
      "        2.24863761e-04,  5.43868728e-03, -4.00960399e-03, -3.36336624e-03,\n",
      "        5.91154862e-03, -3.24730366e-03,  1.70697132e-03,  4.72520571e-03,\n",
      "        1.44637958e-03,  3.25478474e-03,  3.79258441e-03, -1.89648534e-03,\n",
      "       -6.70115172e-04, -3.33244470e-03,  6.44052960e-03, -5.11156442e-03,\n",
      "        1.85280084e-03,  3.30755254e-03,  5.09873591e-03,  4.33384161e-03,\n",
      "        2.43235636e-03,  4.31353040e-03, -3.91127216e-03,  4.73336922e-03,\n",
      "        6.88876142e-04,  0.00000000e+00,  1.57895673e-03,  2.47007376e-03,\n",
      "        1.86528871e-03, -3.46762058e-03,  2.42804969e-03, -1.37586889e-04,\n",
      "       -1.85114134e-03,  0.00000000e+00,  0.00000000e+00, -1.41211436e-03,\n",
      "        5.46995178e-03, -3.39367613e-03,  3.94711131e-03,  3.18005774e-03,\n",
      "       -5.11971419e-04,  2.46643391e-03, -2.44511478e-03,  5.16675459e-03,\n",
      "       -2.61249067e-03, -1.58803468e-03,  1.24099408e-03,  1.47791195e-03,\n",
      "        2.53960188e-03,  2.04351451e-03, -5.70338499e-03,  2.76096864e-03,\n",
      "        3.65881785e-03, -1.60916289e-03,  3.59570887e-03, -7.68503291e-04,\n",
      "       -4.60786372e-03, -2.51274090e-03, -1.78236340e-04,  7.53808115e-03],\n",
      "      dtype=float32)>]\n",
      "updated weights\n",
      "[<tf.Variable 'critic/dense_4/kernel:0' shape=(8, 128) dtype=float32, numpy=\n",
      "array([[ 0.00237525,  0.0078512 , -0.01724499, ...,  0.0115803 ,\n",
      "         0.022772  , -0.04706287],\n",
      "       [-0.00969595,  0.00585578,  0.01052457, ..., -0.00487111,\n",
      "        -0.01816537,  0.00831917],\n",
      "       [ 0.0081198 , -0.00301005,  0.01317033, ..., -0.00394173,\n",
      "         0.01516552,  0.00278392],\n",
      "       ...,\n",
      "       [-0.00636525, -0.00464775,  0.00025596, ..., -0.00326886,\n",
      "         0.0008102 , -0.01244009],\n",
      "       [ 0.0049195 , -0.00667758, -0.002179  , ..., -0.00545166,\n",
      "         0.00582104,  0.00608449],\n",
      "       [ 0.01571611,  0.02401898, -0.01277834, ..., -0.00598551,\n",
      "        -0.00671953,  0.00330386]], dtype=float32)>, <tf.Variable 'critic/dense_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 5.17233415e-03,  6.45415951e-03,  5.17851301e-03, -2.68052705e-03,\n",
      "        5.60980570e-03,  2.04866659e-03,  3.25845438e-04,  2.97503243e-03,\n",
      "        5.96688886e-04, -4.12273966e-03,  7.02025369e-03, -3.96413589e-03,\n",
      "        2.72993790e-03,  6.12883456e-03,  5.34625258e-03, -3.72244511e-03,\n",
      "       -6.34388905e-03,  3.97722982e-03, -8.23248003e-04,  3.71913682e-03,\n",
      "        5.75257582e-05,  4.66340221e-03, -1.27007777e-03,  7.39189191e-03,\n",
      "        3.96852009e-03,  4.88856900e-03, -5.50193945e-03,  4.38634888e-04,\n",
      "        3.01473634e-03,  7.30215712e-03, -2.72168382e-03, -6.31048949e-03,\n",
      "        6.34930190e-03, -7.52090360e-04, -4.76787449e-04,  5.21082105e-03,\n",
      "        5.12104807e-03,  3.58296704e-04, -3.17884173e-04, -6.38720905e-03,\n",
      "        6.99924538e-04, -4.43807745e-04, -7.12020509e-03,  5.28200576e-03,\n",
      "        4.87646041e-03, -5.52663393e-03,  0.00000000e+00,  1.34872738e-03,\n",
      "       -2.70671328e-03,  4.53292439e-03,  5.09012118e-03,  6.69681095e-03,\n",
      "        0.00000000e+00, -6.49280939e-03, -6.04584534e-03,  2.89631495e-03,\n",
      "        2.10576807e-03,  2.33937404e-03,  2.90061231e-03, -6.60377275e-03,\n",
      "        5.22187958e-03,  6.03028107e-03, -2.44745240e-03, -6.26575574e-03,\n",
      "        4.92596766e-03,  2.72531831e-03,  5.72860241e-03, -3.76176415e-03,\n",
      "        7.21878023e-04,  5.88932866e-03, -4.24070749e-03, -3.36957676e-03,\n",
      "        6.46877196e-03, -3.40029667e-03,  2.20624264e-03,  5.32833301e-03,\n",
      "        2.01489939e-03,  3.81041877e-03,  4.30897018e-03, -1.60975172e-03,\n",
      "       -6.51922950e-04, -2.96633225e-03,  7.04096025e-03, -5.41203655e-03,\n",
      "        2.29565101e-03,  3.82444449e-03,  5.66955842e-03,  4.91707446e-03,\n",
      "        2.68554292e-03,  4.87995939e-03, -4.09564329e-03,  5.26763592e-03,\n",
      "        1.20672141e-03,  0.00000000e+00,  2.07907031e-03,  2.72719422e-03,\n",
      "        2.05936190e-03, -3.30067473e-03,  2.95218499e-03,  3.10168252e-06,\n",
      "       -2.05802196e-03,  0.00000000e+00,  0.00000000e+00, -1.15838740e-03,\n",
      "        5.92180435e-03, -3.68081266e-03,  4.50482452e-03,  3.53896408e-03,\n",
      "       -1.07888365e-04,  2.72619771e-03, -2.69963196e-03,  5.51931653e-03,\n",
      "       -2.62796832e-03, -1.51482108e-03,  1.81362871e-03,  2.07051169e-03,\n",
      "        3.04355100e-03,  2.42598681e-03, -6.03444781e-03,  3.34438682e-03,\n",
      "        4.20982623e-03, -1.84090598e-03,  3.99344927e-03, -2.65673210e-04,\n",
      "       -4.85343905e-03, -2.79639754e-03, -3.63184663e-04,  8.11205711e-03],\n",
      "      dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNikis idea what the problem:\\n- Actor_loss needs to be eager tensor dtpye float32 shit\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ppo_agent = Agent()\n",
    "ppo_agent.run()\n",
    "# ppo_agent.collect_train_data()\n",
    "# data = storage.get_episodes()\n",
    "# #print(data)\n",
    "# print(ppo_agent.update_policy(data[0], actor, critic, optimizer, clip_ratio))\n",
    "\n",
    "'''\n",
    "Nikis idea what the problem:\n",
    "- Actor_loss needs to be eager tensor dtpye float32 shit\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6ce7daced66c1b43e67ee1266804bcc56425fa4e39cc8300d2c0d41d8b5ef83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ann')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
